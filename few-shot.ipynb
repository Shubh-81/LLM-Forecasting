{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e6cd8b8a961685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T06:40:53.404891Z",
     "start_time": "2024-03-02T06:40:48.006058Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (0.26.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from accelerate) (1.23.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from accelerate) (23.2)\r\n",
      "Requirement already satisfied: psutil in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from accelerate) (5.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from accelerate) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from accelerate) (2.2.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from accelerate) (0.20.2)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from accelerate) (0.4.1)\r\n",
      "Requirement already satisfied: filelock in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\r\n",
      "Requirement already satisfied: requests in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from huggingface-hub->accelerate) (4.66.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shubhagarwal/anaconda3/envs/llmtime/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes>=0.39.0 -q\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T07:05:30.216700Z",
     "start_time": "2024-03-02T07:05:29.995774Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain import HuggingFaceHub\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322495b4d61d8d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T07:02:34.004727Z",
     "start_time": "2024-03-02T07:02:33.997316Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6024b9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/shubhagarwal/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cec84b3ef9d2cab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T07:02:34.488239Z",
     "start_time": "2024-03-02T07:02:34.470774Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Scaler:\n",
    "    transform: callable = lambda x: x\n",
    "    inv_transform: callable = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef151cbbbbb3802d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T07:05:32.971103Z",
     "start_time": "2024-03-02T07:05:32.932519Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LLMTime:\n",
    "    \n",
    "    def __init__(self, train, test, alpha=0.95, beta=0.3, batch_length=400, basic=False, temperature=0.5, do_sample=True, model_name=\"mistralai/Mistral-7B-v0.1\", repetition_penalty=1.0, ollama = False, num_samples=10):\n",
    "        self.ollama = ollama\n",
    "        self.model_name = model_name\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.batch_length = batch_length\n",
    "        self.basic = basic\n",
    "        self.temperature = temperature\n",
    "        self.do_sample = do_sample\n",
    "        self.repetition_penalty = repetition_penalty\n",
    "        self.scalers = None\n",
    "        self.input_str = None\n",
    "        self.test_str = None\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.good_tokens = None\n",
    "        self.bad_tokens = None\n",
    "        self.output = None\n",
    "        self.transformed_output_arr = None\n",
    "        self.num_samples = num_samples\n",
    "        self.preprocess_data()\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_scaler(history, alpha=0.95, beta=0.3, basic=False):\n",
    "        history = history[~np.isnan(history)]\n",
    "        if basic:\n",
    "            q = np.maximum(np.quantile(np.abs(history), alpha),.01)\n",
    "            def transform(x):\n",
    "                return x / q\n",
    "            def inv_transform(x):\n",
    "                return x * q\n",
    "        else:\n",
    "            min_ = np.min(history) - beta*(np.max(history)-np.min(history))\n",
    "            q = np.quantile(history-min_, alpha)\n",
    "            if q == 0:\n",
    "                q = 1\n",
    "            def transform(x):\n",
    "                return (x - min_) / q\n",
    "            def inv_transform(x):\n",
    "                return x * q + min_\n",
    "        return Scaler(transform=transform, inv_transform=inv_transform)\n",
    "    \n",
    "    def convert_array_to_string(self, arr):\n",
    "        rounded_values = [round(val * 1000) for val in arr]\n",
    "        str_values = [str(val) for val in rounded_values]\n",
    "        result_string = \",\".join(str_values)\n",
    "        return result_string\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        train = self.train\n",
    "        test = self.test\n",
    "        if not isinstance(train, list):\n",
    "            train = [train]\n",
    "            test = [test]\n",
    "        n_val = len(train)\n",
    "        for i in range(len(train)):\n",
    "            if not isinstance(train[i], pd.Series):\n",
    "                train[i] = pd.Series(train[i], index=pd.RangeIndex(len(train[i])))\n",
    "                test[i] = pd.Series(test[i], index=pd.RangeIndex(len(train[i]), len(test[i])+len(train[i])))\n",
    "        alpha = self.alpha\n",
    "        beta = self.beta\n",
    "        basic = self.basic\n",
    "        self.scalers = [self.get_scaler(train[i].values, alpha=alpha, beta=beta, basic=basic) for i in range(len(train))]\n",
    "        input_arrs = [train[i].values for i in range(len(train))]\n",
    "        transformed_input_arrs = np.array([scaler.transform(input_array) for input_array, scaler in zip(input_arrs, self.scalers)])\n",
    "        input_str = self.convert_array_to_string(transformed_input_arrs[0])\n",
    "        test_arrs = [test[i].values for i in range(len(test))]\n",
    "        transformed_test_arrs = np.array([scaler.transform(input_array) for input_array, scaler in zip(test_arrs, self.scalers)])\n",
    "        test_str = self.convert_array_to_string(transformed_test_arrs[0])\n",
    "        self.input_str = input_str\n",
    "        self.test_str = test_str\n",
    "        return input_str, test_str, self.scalers\n",
    "    \n",
    "    def few_shot(self):\n",
    "        input_str = self.input_str\n",
    "        examples = []\n",
    "        batch_length = self.batch_length\n",
    "        for i in range(batch_length, len(input_str) - batch_length, batch_length):\n",
    "            examples.append({\n",
    "                \"input\": input_str[i-batch_length:i],\n",
    "                \"output\": input_str[i:i+batch_length//5]\n",
    "            })\n",
    "        example_template = \"\"\"\n",
    "        {{input}} -> {{output}}\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate.from_template(example_template, template_format='jinja2')\n",
    "        \n",
    "        few_shot_prompt = FewShotPromptTemplate(\n",
    "            examples=examples,\n",
    "            example_prompt=prompt,\n",
    "            prefix=\"Predict the next token value, outputting only digits or commas, use the examples given as reference: \",\n",
    "            suffix=\"{input} ->\",\n",
    "            input_variables=[\"input\"],\n",
    "            example_separator=\"\",\n",
    "        )\n",
    "        if not self.ollama:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, padding_side=\"left\")\n",
    "            good_tokens_str = list(\"0123456789,\")\n",
    "            good_tokens = [self.tokenizer.convert_tokens_to_ids(token) for token in good_tokens_str]\n",
    "            self.bad_tokens = [i for i in range(len(self.tokenizer)) if i not in good_tokens]\n",
    "            self.good_tokens = [i for i in range(len(self.tokenizer)) if i in good_tokens]\n",
    "            self.model = HuggingFaceHub(repo_id=self.model_name, model_kwargs={\n",
    "                \"temperature\": self.temperature, \n",
    "                \"do_sample\": self.do_sample,\n",
    "                \"repetition_penalty\": self.repetition_penalty,\n",
    "                \"max_new_tokens\": self.batch_length//5, \n",
    "                \"min_new_tokens\": self.batch_length//5,\n",
    "                \"force_words_ids\": [[t] for t in self.good_tokens],\n",
    "                \"bad_words_ids\": [[t] for t in self.bad_tokens],\n",
    "                \"num_beams\": 2,\n",
    "                \"top_k\": 20\n",
    "            })\n",
    "        else:\n",
    "            self.model = Ollama(model=self.model_name)\n",
    "        chain = LLMChain(llm=self.model, prompt=few_shot_prompt)\n",
    "        output = \"\"\n",
    "        inp = input_str\n",
    "        i = 0\n",
    "        while len(output) < len(self.test_str) and i < 1000:\n",
    "            print(len(output), len(self.test_str))\n",
    "            i+=1\n",
    "            out = chain.predict(input=inp[-self.batch_length:])\n",
    "            sub = out.split('>')[-1]\n",
    "            sub = sub.strip()\n",
    "            sub = sub.replace('\\n', '').replace('\\r', '')\n",
    "            print(f'Output {i} : {sub}')\n",
    "            pattern = r'^[0-9,]+$'\n",
    "            if not bool(re.match(pattern, sub)):\n",
    "                break\n",
    "            firstComma = sub.find(',')\n",
    "            lastComma = sub.rfind(',')\n",
    "            if firstComma == -1 or lastComma == -1 or firstComma == lastComma:\n",
    "                break\n",
    "            sub = sub[firstComma+1:lastComma]\n",
    "            if len(sub) == 0:\n",
    "                break\n",
    "            output = output + ',' + sub\n",
    "            inp = inp[:inp.rfind(',')]\n",
    "            inp = inp + ',' + sub\n",
    "            print(output)\n",
    "            print(len(output), len(self.test_str))\n",
    "        self.output = output\n",
    "        return output\n",
    "      \n",
    "    @staticmethod    \n",
    "    def invert_string_to_array(string_values):\n",
    "        string_values = string_values.replace(\" \", \"\")\n",
    "        if string_values[-1] == ',':\n",
    "            string_values = string_values[:len(string_values) - 1]\n",
    "        str_values_list = string_values.split(',')\n",
    "        float_values = [float(val) if val.strip() != '' else 0.0 for val in str_values_list]\n",
    "        original_values = [val / 1000 for val in float_values]\n",
    "        return original_values\n",
    "\n",
    "    def get_original_array(self, output_str):\n",
    "        output_arr = self.invert_string_to_array(string_values=output_str)\n",
    "        output_arr = np.array(output_arr)\n",
    "        transformed_output_arr = self.scalers[0].inv_transform(output_arr)\n",
    "        self.transformed_output_arr = transformed_output_arr\n",
    "        return transformed_output_arr\n",
    "    \n",
    "    def plot(self, input, outputs, m):\n",
    "        model_parameters = {\n",
    "            \"alpha\": self.alpha,\n",
    "            \"beta\": self.beta,\n",
    "            \"batch_length\": self.batch_length,\n",
    "            \"basic\": self.basic,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"do_sample\": self.do_sample,\n",
    "            \"repetition_penalty\": self.repetition_penalty,\n",
    "            \"num_samples\": self.num_samples\n",
    "        }\n",
    "\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        plt.title(f\"Few Shot {self.model_name}\")\n",
    "        plt.axvline(x=m, color='k', linestyle='--', label='Train-Test Split')\n",
    "        min_output = np.min(outputs, axis=0)\n",
    "        max_output = np.max(outputs, axis=0)\n",
    "        median_output = np.median(outputs, axis=0)\n",
    "        mean_output = np.mean(outputs, axis=0)\n",
    "        k = min(len(input), len(median_output))\n",
    "        input = input[:k]\n",
    "        median_output = median_output[:k]\n",
    "        mean_output = mean_output[:k]\n",
    "        min_output = min_output[:k]\n",
    "        max_output = max_output[:k]\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            plt.plot(outputs[i][:k], color='darkgray', alpha=0.5, label='_nolegend_')\n",
    "\n",
    "        plt.plot(min_output, color='green', linestyle='--', label='Min Predicted')\n",
    "        plt.plot(max_output, color='orange', linestyle='--', label='Max Predicted')\n",
    "        plt.plot(median_output, color='red', label='Median Predicted')\n",
    "        plt.plot(mean_output, color='red', label='Mean Predicted')\n",
    "\n",
    "        min_input = np.min(input)\n",
    "        max_input = np.max(input)\n",
    "        plt.ylim(int(0.99*min_input), int(1.01*max_input))\n",
    "\n",
    "        plt.plot(input, color='blue', label='Actual')\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Time')\n",
    "        sns.set_palette(\"husl\")\n",
    "        print(\"Here\")\n",
    "        print(len(input[-(len(input)-m):]), len(median_output[-(len(median_output)-m):]))\n",
    "        mae = mean_absolute_error(input[-(len(input)-m):], median_output[-(len(median_output)-m):])\n",
    "        rmse = np.sqrt(mean_squared_error(input[-(len(input)-m):], median_output[-(len(median_output)-m):]))\n",
    "        std_dev = np.std(outputs, axis=0)\n",
    "\n",
    "        error_text = f\"\\n\\nMedian MAE: {mae:.2f}\\nMedian RMSE: {rmse:.2f}\\nStandard Deviation: {np.mean(std_dev):.2f}\"\n",
    "        ax.text(1.05, 0.4, error_text, transform=ax.transAxes, fontsize=10, verticalalignment='center')\n",
    "        textstr = '\\n'.join([f\"{key}: {value}\" for key, value in model_parameters.items()])\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        ax.text(1.05, 0.6, textstr, transform=ax.transAxes, fontsize=10, verticalalignment='center', bbox=props)\n",
    "\n",
    "        model_name = self.model_name.split('/')[1]\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        random_number = np.random.randint(0, 1000)\n",
    "        filename = f\"plts/{model_name}-few-shot-{current_time}-{random_number}.png\"\n",
    "\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved as {filename}\")\n",
    "    \n",
    "    def run(self):\n",
    "        outputs =[]\n",
    "        for i in range(self.num_samples):\n",
    "            output = self.few_shot()\n",
    "            outputs.append(output)\n",
    "        r = np.array(outputs)\n",
    "        self.plot_and_return(r)\n",
    "        return r\n",
    "        \n",
    "    def plot_and_return(self, outputs):\n",
    "        l = []\n",
    "        input_arr = self.get_original_array(self.input_str + ',' + self.test_str)\n",
    "        inp = self.get_original_array(self.input_str)\n",
    "        m = len(inp)\n",
    "        min_len = 9999999999\n",
    "        for i, output in enumerate(outputs):\n",
    "            if output[0] == ',':\n",
    "                output = output[1:]\n",
    "            transformed_output_arr = self.get_original_array(self.input_str + ',' + output)\n",
    "            min_len = min(min_len, len(transformed_output_arr))\n",
    "            l.append(transformed_output_arr)\n",
    "        input_arr = input_arr[:min_len]\n",
    "        for i, x in enumerate(l):\n",
    "            l[i] = x[:min_len]\n",
    "        print(l)\n",
    "        self.plot(input_arr, np.array(l), m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d24702f606a00cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T07:06:42.237576Z",
     "start_time": "2024-03-02T07:06:42.219751Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1557,) (668,) (2225,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "co2 = fetch_openml(data_id=41187, as_frame=True, parser='auto')\n",
    "co2_data = co2.frame\n",
    "co2_data[\"date\"] = pd.to_datetime(co2_data[[\"year\", \"month\", \"day\"]])\n",
    "co2_data = co2_data.sort_values(by=\"date\")\n",
    "co2_data = co2_data[[\"date\", \"co2\"]].set_index(\"date\")\n",
    "co2_data=co2_data.squeeze()\n",
    "train_2, test_2 = co2_data[:int(0.7*len(co2_data))], co2_data[int(0.7*len(co2_data)):]\n",
    "print(train_2.shape,test_2.shape,co2_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e395a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>#Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Month  #Passengers\n",
       "0  1949-01          112\n",
       "1  1949-02          118\n",
       "2  1949-03          132\n",
       "3  1949-04          129\n",
       "4  1949-05          121"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('AirPassengers.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c36f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('Month')\n",
    "data = data.squeeze()\n",
    "train, test = data['#Passengers'][:int(0.7*len(data))], data['#Passengers'][int(0.7*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b062ee71194b920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:59:05.032236Z",
     "start_time": "2024-03-02T08:59:04.932785Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "llm_time = LLMTime(train, test, alpha=0.95, beta=0.3, batch_length=50, basic=False, temperature=0.7, do_sample=True, ollama=False, repetition_penalty=1, num_samples=1, model_name=\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = llm_time.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
