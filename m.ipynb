{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-25T11:39:49.217109Z",
     "start_time": "2024-01-25T11:39:48.516399Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Setting hyperparameters for llama2"
   ],
   "id": "19f24295e90ad51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:41:57.215788Z",
     "start_time": "2024-01-25T11:41:56.654578Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class SerializerSettings:\n",
    "    \"\"\"\n",
    "    Settings for serialization of numbers.\n",
    "\n",
    "    Attributes:\n",
    "    - base (int): The base for number representation.\n",
    "    - prec (int): The precision after the 'decimal' point in the base representation.\n",
    "    - signed (bool): If True, allows negative numbers. Default is False.\n",
    "    - fixed_length (bool): If True, ensures fixed length of serialized string. Default is False.\n",
    "    - max_val (float): Maximum absolute value of number for serialization.\n",
    "    - time_sep (str): Separator for different time steps.\n",
    "    - bit_sep (str): Separator for individual digits.\n",
    "    - plus_sign (str): String representation for positive sign.\n",
    "    - minus_sign (str): String representation for negative sign.\n",
    "    - half_bin_correction (bool): If True, applies half bin correction during deserialization. Default is True.\n",
    "    - decimal_point (str): String representation for the decimal point.\n",
    "    \"\"\"\n",
    "    base: int = 10\n",
    "    prec: int = 3\n",
    "    signed: bool = True\n",
    "    fixed_length: bool = False\n",
    "    max_val: float = 1e7\n",
    "    time_sep: str = ' ,'\n",
    "    bit_sep: str = ' '\n",
    "    plus_sign: str = ''\n",
    "    minus_sign: str = ' -'\n",
    "    half_bin_correction: bool = True\n",
    "    decimal_point: str = ''\n",
    "    missing_str: str = ' Nan'"
   ],
   "id": "f5ffbc94365f40fd",
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:41:58.041819Z",
     "start_time": "2024-01-25T11:41:58.021367Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "llama2_hypers = dict(\n",
    "    temp=0.7,\n",
    "    alpha=0.95,\n",
    "    beta=0.3,\n",
    "    basic=False,\n",
    "    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True)\n",
    ")"
   ],
   "id": "5c258805d42f9272",
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Getting the CO2 MonaLua Dataset"
   ],
   "id": "817cc45f4004d0b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:48:21.338283Z",
     "start_time": "2024-01-25T11:48:21.291396Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1557,) (668,) (2225,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "co2 = fetch_openml(data_id=41187, as_frame=True, parser='auto')\n",
    "co2_data = co2.frame\n",
    "co2_data[\"date\"] = pd.to_datetime(co2_data[[\"year\", \"month\", \"day\"]])\n",
    "co2_data = co2_data.sort_values(by=\"date\")\n",
    "co2_data = co2_data[[\"date\", \"co2\"]].set_index(\"date\")\n",
    "\n",
    "co2_data=co2_data.squeeze()\n",
    "train, test = co2_data[:int(0.7*len(co2_data))], co2_data[int(0.7*len(co2_data)):]\n",
    "print(train.shape,test.shape,co2_data.shape)"
   ],
   "id": "dc8b072ba832d54",
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:46:32.480863Z",
     "start_time": "2024-01-25T11:46:32.461466Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "import itertools, functools\n",
    "import operator\n",
    "\n",
    "class NoGetItLambdaDict(dict):\n",
    "    \"\"\" Regular dict, but refuses to __getitem__ pretending\n",
    "        the element is not there and throws a KeyError\n",
    "        if the value is a non string iterable or a lambda \"\"\"\n",
    "    def __init__(self,d={}):\n",
    "        super().__init__()\n",
    "        for k,v in d.items():\n",
    "            if isinstance(v,dict):\n",
    "                self[k] = NoGetItLambdaDict(v)\n",
    "            else:\n",
    "                self[k] = v\n",
    "    def __getitem__(self, key):\n",
    "        value = super().__getitem__(key)\n",
    "        if callable(value) and value.__name__ == \"<lambda>\":\n",
    "            raise LookupError(\"You shouldn't try to retrieve lambda {} from this dict\".format(value))\n",
    "        if isinstance(value,Iterable) and not isinstance(value,(str,bytes,dict,tuple)):\n",
    "            raise LookupError(\"You shouldn't try to retrieve iterable {} from this dict\".format(value))\n",
    "        return value\n",
    "        \n",
    "    # pop = __readonly__\n",
    "    # popitem = __readonly__\n",
    "\n",
    "def flatten(d, parent_key='', sep='/'):\n",
    "    \"\"\"An invertible dictionary flattening operation that does not clobber objs\"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict) and v: # non-empty dict\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def unflatten(d,sep='/'):\n",
    "    \"\"\"Take a dictionary with keys {'k1/k2/k3':v} to {'k1':{'k2':{'k3':v}}}\n",
    "        as outputted by flatten \"\"\"\n",
    "    out_dict={}\n",
    "    for k,v in d.items():\n",
    "        if isinstance(k,str):\n",
    "            keys = k.split(sep)\n",
    "            dict_to_modify = out_dict\n",
    "            for partial_key in keys[:-1]:\n",
    "                try: dict_to_modify = dict_to_modify[partial_key]\n",
    "                except KeyError:\n",
    "                    dict_to_modify[partial_key] = {}\n",
    "                    dict_to_modify = dict_to_modify[partial_key]\n",
    "                # Base level reached\n",
    "            if keys[-1] in dict_to_modify:\n",
    "                dict_to_modify[keys[-1]].update(v)\n",
    "            else:\n",
    "                dict_to_modify[keys[-1]] = v\n",
    "        else: out_dict[k]=v\n",
    "    return out_dict\n",
    "\n",
    "from collections import defaultdict\n",
    "def sample_config(config_spec):\n",
    "    \"\"\" Generates configs from the config spec.\n",
    "        It will apply lambdas that depend on the config and sample from any\n",
    "        iterables, make sure that no elements in the generated config are meant to \n",
    "        be iterable or lambdas, strings are allowed.\"\"\"\n",
    "    cfg_all = config_spec\n",
    "    more_work=True\n",
    "    i=0\n",
    "    while more_work:\n",
    "        cfg_all, more_work = _sample_config(cfg_all,NoGetItLambdaDict(cfg_all))\n",
    "        i+=1\n",
    "        if i>10: \n",
    "            raise RecursionError(\"config dependency unresolvable with {}\".format(cfg_all))\n",
    "    out = defaultdict(dict)\n",
    "    out.update(cfg_all)\n",
    "    return out\n",
    "\n",
    "def _sample_config(config_spec,cfg_all):\n",
    "    cfg = {}\n",
    "    more_work = False\n",
    "    for k,v in config_spec.items():\n",
    "        if isinstance(v,dict):\n",
    "            new_dict,extra_work = _sample_config(v,cfg_all)\n",
    "            cfg[k] = new_dict\n",
    "            more_work |= extra_work\n",
    "        elif isinstance(v,Iterable) and not isinstance(v,(str,bytes,dict,tuple)):\n",
    "            cfg[k] = random.choice(v)\n",
    "        elif callable(v) and v.__name__ == \"<lambda>\":\n",
    "            try:cfg[k] = v(cfg_all)\n",
    "            except (KeyError, LookupError,Exception):\n",
    "                cfg[k] = v # is used isntead of the variable it returns\n",
    "                more_work = True\n",
    "        else: cfg[k] = v\n",
    "    return cfg, more_work\n",
    "\n",
    "import random\n",
    "class FixedNumpySeed(object):\n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "    def __enter__(self):\n",
    "        self.np_rng_state = np.random.get_state()\n",
    "        np.random.seed(self.seed)\n",
    "        self.rand_rng_state = random.getstate()\n",
    "        random.seed(self.seed)\n",
    "    def __exit__(self, *args):\n",
    "        np.random.set_state(self.np_rng_state)\n",
    "        random.setstate(self.rand_rng_state)\n",
    "\n",
    "class grid_iter(object):\n",
    "    \"\"\" Defines a length which corresponds to one full pass through the grid\n",
    "        defined by grid variables in config_spec, but the iterator will continue iterating\n",
    "        past that by repeating over the grid variables\"\"\"\n",
    "    def __init__(self,config_spec,num_elements=-1,shuffle=True):\n",
    "        self.cfg_flat = flatten(config_spec)\n",
    "        is_grid_iterable = lambda v: (isinstance(v,Iterable) and not isinstance(v,(str,bytes,dict,tuple)))\n",
    "        iterables = sorted({k:v for k,v in self.cfg_flat.items() if is_grid_iterable(v)}.items())\n",
    "        if iterables: self.iter_keys,self.iter_vals = zip(*iterables)\n",
    "        else: self.iter_keys,self.iter_vals = [],[[]]\n",
    "        self.vals = list(itertools.product(*self.iter_vals))\n",
    "        if shuffle:\n",
    "            with FixedNumpySeed(0): random.shuffle(self.vals)\n",
    "        self.num_elements = num_elements if num_elements>=0 else (-1*num_elements)*len(self)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i=0\n",
    "        self.vals_iter = iter(self.vals)\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        self.i+=1\n",
    "        if self.i > self.num_elements: raise StopIteration\n",
    "        if not self.vals: v = []\n",
    "        else:\n",
    "            try: v = next(self.vals_iter)\n",
    "            except StopIteration:\n",
    "                self.vals_iter = iter(self.vals)\n",
    "                v = next(self.vals_iter)\n",
    "        chosen_iter_params = dict(zip(self.iter_keys,v))\n",
    "        self.cfg_flat.update(chosen_iter_params)\n",
    "        return sample_config(unflatten(self.cfg_flat))\n",
    "    def __len__(self):\n",
    "        product = functools.partial(functools.reduce, operator.mul)\n",
    "        return product(len(v) for v in self.iter_vals) if self.vals else 1"
   ],
   "id": "335f8bf51b409dc0",
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:46:47.854349Z",
     "start_time": "2024-01-25T11:46:47.821312Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[defaultdict(dict,\n",
       "             {'model': 'llama-7b',\n",
       "              'temp': 0.7,\n",
       "              'alpha': 0.95,\n",
       "              'beta': 0.3,\n",
       "              'basic': False,\n",
       "              'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=' ,', bit_sep=' ', plus_sign='', minus_sign=' -', half_bin_correction=True, decimal_point='', missing_str=' Nan')})]"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "out = {}\n",
    "hypers = list(grid_iter({'model': 'llama-7b', **llama2_hypers}))\n",
    "num_samples = 10\n",
    "hypers"
   ],
   "id": "ea494a071906c170",
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:48:29.054660Z",
     "start_time": "2024-01-25T11:48:29.027748Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if isinstance(hypers,dict):\n",
    "    hypers = list(grid_iter(hypers))\n",
    "else:\n",
    "    assert isinstance(hypers, list), 'hypers must be a list or dict'\n",
    "if not isinstance(train, list):\n",
    "    train = [train]\n",
    "    test = [test]\n",
    "n_val = len(train)"
   ],
   "id": "f6dac48933f01caf",
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:48:38.843320Z",
     "start_time": "2024-01-25T11:48:38.809881Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[date\n",
       " 1989-03-18    353.5\n",
       " 1989-03-25    354.4\n",
       " 1989-04-01    354.5\n",
       " 1989-04-08    355.0\n",
       " 1989-04-15    355.4\n",
       "               ...  \n",
       " 2001-12-01    370.3\n",
       " 2001-12-08    370.8\n",
       " 2001-12-15    371.2\n",
       " 2001-12-22    371.3\n",
       " 2001-12-29    371.5\n",
       " Name: co2, Length: 668, dtype: float64]"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "test"
   ],
   "id": "71c32a7abc7d7963",
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:49:05.910751Z",
     "start_time": "2024-01-25T11:49:05.869093Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_hyper = hypers[0]\n",
    "best_val_nll = float('inf')"
   ],
   "id": "d5a63c5db6cc02",
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:49:07.597274Z",
     "start_time": "2024-01-25T11:49:07.578430Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'model': 'llama-7b',\n",
       "             'temp': 0.7,\n",
       "             'alpha': 0.95,\n",
       "             'beta': 0.3,\n",
       "             'basic': False,\n",
       "             'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=' ,', bit_sep=' ', plus_sign='', minus_sign=' -', half_bin_correction=True, decimal_point='', missing_str=' Nan')})"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "best_hyper"
   ],
   "id": "1330a1d00a97a9cb",
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:54:43.293361Z",
     "start_time": "2024-01-25T11:54:43.249770Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    if not isinstance(train[i], pd.Series):\n",
    "        train[i] = pd.Series(train[i], index=pd.RangeIndex(len(train[i])))\n",
    "        test[i] = pd.Series(test[i], index=pd.RangeIndex(len(train[i]), len(test[i])+len(train[i])))"
   ],
   "id": "e9266773c5aa9d08",
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:55:02.837671Z",
     "start_time": "2024-01-25T11:55:02.808052Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[date\n",
       " 1958-03-29    316.1\n",
       " 1958-04-05    317.3\n",
       " 1958-04-12    317.6\n",
       " 1958-04-19    317.5\n",
       " 1958-04-26    316.4\n",
       "               ...  \n",
       " 1989-02-11    352.6\n",
       " 1989-02-18    353.2\n",
       " 1989-02-25    353.4\n",
       " 1989-03-04    353.1\n",
       " 1989-03-11    353.4\n",
       " Name: co2, Length: 1557, dtype: float64]"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 26
    }
   ],
   "source": [
    "train"
   ],
   "id": "400efbd4cbf1225e",
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T11:55:05.853385Z",
     "start_time": "2024-01-25T11:55:05.828017Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[date\n",
       " 1989-03-18    353.5\n",
       " 1989-03-25    354.4\n",
       " 1989-04-01    354.5\n",
       " 1989-04-08    355.0\n",
       " 1989-04-15    355.4\n",
       "               ...  \n",
       " 2001-12-01    370.3\n",
       " 2001-12-08    370.8\n",
       " 2001-12-15    371.2\n",
       " 2001-12-22    371.3\n",
       " 2001-12-29    371.5\n",
       " Name: co2, Length: 668, dtype: float64]"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 27
    }
   ],
   "source": [
    "test"
   ],
   "id": "799dbdfe67f52e3c",
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T12:58:10.270666Z",
     "start_time": "2024-01-25T12:58:10.252978Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Scaler:\n",
    "    \"\"\"\n",
    "    Represents a data scaler with transformation and inverse transformation functions.\n",
    "\n",
    "    Attributes:\n",
    "        transform (callable): Function to apply transformation.\n",
    "        inv_transform (callable): Function to apply inverse transformation.\n",
    "    \"\"\"\n",
    "    transform: callable = lambda x: x\n",
    "    inv_transform: callable = lambda x: x\n",
    "\n",
    "def get_scaler(history, alpha=0.95, beta=0.3, basic=False):\n",
    "    \"\"\"\n",
    "    Generate a Scaler object based on given history data.\n",
    "\n",
    "    Args:\n",
    "        history (array-like): Data to derive scaling from.\n",
    "        alpha (float, optional): Quantile for scaling. Defaults to .95.\n",
    "        # Truncate inputs\n",
    "        tokens = [tokeniz]\n",
    "        beta (float, optional): Shift parameter. Defaults to .3.\n",
    "        basic (bool, optional): If True, no shift is applied, and scaling by values below 0.01 is avoided. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Scaler: Configured scaler object.\n",
    "    \"\"\"\n",
    "    history = history[~np.isnan(history)]\n",
    "    if basic:\n",
    "        q = np.maximum(np.quantile(np.abs(history), alpha),.01)\n",
    "        def transform(x):\n",
    "            return x / q\n",
    "        def inv_transform(x):\n",
    "            return x * q\n",
    "    else:\n",
    "        min_ = np.min(history) - beta*(np.max(history)-np.min(history))\n",
    "        q = np.quantile(history-min_, alpha)\n",
    "        if q == 0:\n",
    "            q = 1\n",
    "        def transform(x):\n",
    "            return (x - min_) / q\n",
    "        def inv_transform(x):\n",
    "            return x * q + min_\n",
    "    return Scaler(transform=transform, inv_transform=inv_transform)"
   ],
   "id": "6b4bfdbc95f00959",
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T12:58:11.023118Z",
     "start_time": "2024-01-25T12:58:10.995996Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "alpha=0.95\n",
    "beta=0.3\n",
    "basic=False\n",
    "scalers = [get_scaler(train[i].values, alpha=alpha, beta=beta, basic=basic) for i in range(len(train))]"
   ],
   "id": "d8f03c7450a32350",
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T12:58:29.636209Z",
     "start_time": "2024-01-25T12:58:29.613755Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scaler(transform=<function get_scaler.<locals>.transform at 0x7fddb0cb6a60>, inv_transform=<function get_scaler.<locals>.inv_transform at 0x7fddb0cb1c10>)"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 38
    }
   ],
   "source": [
    "scalers[0]"
   ],
   "id": "c1067f557f2eed5",
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T13:02:25.223300Z",
     "start_time": "2024-01-25T13:02:25.196274Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([316.1, 317.3, 317.6, ..., 353.4, 353.1, 353.4])]"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 42
    }
   ],
   "source": [
    "input_arrs = [train[i].values for i in range(len(train))]\n",
    "input_arrs"
   ],
   "id": "8aa01e1c5fe216cd",
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T13:02:38.940409Z",
     "start_time": "2024-01-25T13:02:38.918361Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transformed_input_arrs = np.array([scaler.transform(input_array) for input_array, scaler in zip(input_arrs, scalers)])"
   ],
   "id": "8b14a51ea12e95c6",
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T13:02:41.818686Z",
     "start_time": "2024-01-25T13:02:41.793321Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31754135, 0.34204615, 0.34817235, ..., 1.07923218, 1.07310598,\n",
       "        1.07923218]])"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 44
    }
   ],
   "source": [
    "transformed_input_arrs"
   ],
   "id": "d6caa523d5930f36",
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T13:12:20.535244Z",
     "start_time": "2024-01-25T13:12:20.505610Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0792321829691647"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 53
    }
   ],
   "source": [
    "transformed_input_arrs[0][-1]"
   ],
   "id": "77693a2fcec83f04",
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T13:07:41.353475Z",
     "start_time": "2024-01-25T13:07:41.317242Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def vec_num2repr(val, base, prec, max_val):\n",
    "    \"\"\"\n",
    "    Convert numbers to a representation in a specified base with precision.\n",
    "\n",
    "    Parameters:\n",
    "    - val (np.array): The numbers to represent.\n",
    "    - base (int): The base of the representation.\n",
    "    - prec (int): The precision after the 'decimal' point in the base representation.\n",
    "    - max_val (float): The maximum absolute value of the number.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Sign and digits in the specified base representation.\n",
    "    \n",
    "    Examples:\n",
    "        With base=10, prec=2:\n",
    "            0.5   ->    50\n",
    "            3.52  ->   352\n",
    "            12.5  ->  1250\n",
    "    \"\"\"\n",
    "    base = float(base)\n",
    "    bs = val.shape[0]\n",
    "    sign = 1 * (val >= 0) - 1 * (val < 0)\n",
    "    val = np.abs(val)\n",
    "    max_bit_pos = int(np.ceil(np.log(max_val) / np.log(base)).item())\n",
    "\n",
    "    before_decimals = []\n",
    "    for i in range(max_bit_pos):\n",
    "        digit = (val / base**(max_bit_pos - i - 1)).astype(int)\n",
    "        before_decimals.append(digit)\n",
    "        val -= digit * base**(max_bit_pos - i - 1)\n",
    "\n",
    "    before_decimals = np.stack(before_decimals, axis=-1)\n",
    "\n",
    "    if prec > 0:\n",
    "        after_decimals = []\n",
    "        for i in range(prec):\n",
    "            digit = (val / base**(-i - 1)).astype(int)\n",
    "            after_decimals.append(digit)\n",
    "            val -= digit * base**(-i - 1)\n",
    "\n",
    "        after_decimals = np.stack(after_decimals, axis=-1)\n",
    "        digits = np.concatenate([before_decimals, after_decimals], axis=-1)\n",
    "    else:\n",
    "        digits = before_decimals\n",
    "    return sign, digits\n",
    "\n",
    "def vec_repr2num(sign, digits, base, prec, half_bin_correction=True):\n",
    "    \"\"\"\n",
    "    Convert a string representation in a specified base back to numbers.\n",
    "\n",
    "    Parameters:\n",
    "    - sign (np.array): The sign of the numbers.\n",
    "    - digits (np.array): Digits of the numbers in the specified base.\n",
    "    - base (int): The base of the representation.\n",
    "    - prec (int): The precision after the 'decimal' point in the base representation.\n",
    "    - half_bin_correction (bool): If True, adds 0.5 of the smallest bin size to the number.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: Numbers corresponding to the given base representation.\n",
    "    \"\"\"\n",
    "    base = float(base)\n",
    "    bs, D = digits.shape\n",
    "    digits_flipped = np.flip(digits, axis=-1)\n",
    "    powers = -np.arange(-prec, -prec + D)\n",
    "    val = np.sum(digits_flipped/base**powers, axis=-1)\n",
    "\n",
    "    if half_bin_correction:\n",
    "        val += 0.5/base**prec\n",
    "\n",
    "    return sign * val\n",
    "\n",
    "def serialize_arr(arr, settings: SerializerSettings):\n",
    "    \"\"\"\n",
    "    Serialize an array of numbers (a time series) into a string based on the provided settings.\n",
    "\n",
    "    Parameters:\n",
    "    - arr (np.array): Array of numbers to serialize.\n",
    "    - settings (SerializerSettings): Settings for serialization.\n",
    "\n",
    "    Returns:\n",
    "    - str: String representation of the array.\n",
    "    \"\"\"\n",
    "    # max_val is only for fixing the number of bits in nunm2repr so it can be vmapped\n",
    "    assert np.all(np.abs(arr[~np.isnan(arr)]) <= settings.max_val), f\"abs(arr) must be <= max_val,\\\n",
    "         but abs(arr)={np.abs(arr)}, max_val={settings.max_val}\"\n",
    "    \n",
    "    if not settings.signed:\n",
    "        assert np.all(arr[~np.isnan(arr)] >= 0), f\"unsigned arr must be >= 0\"\n",
    "        plus_sign = minus_sign = ''\n",
    "    else:\n",
    "        plus_sign = settings.plus_sign\n",
    "        minus_sign = settings.minus_sign\n",
    "    \n",
    "    vnum2repr = partial(vec_num2repr,base=settings.base,prec=settings.prec,max_val=settings.max_val)\n",
    "    sign_arr, digits_arr = vnum2repr(np.where(np.isnan(arr),np.zeros_like(arr),arr))\n",
    "    ismissing = np.isnan(arr)\n",
    "    \n",
    "    def tokenize(arr):\n",
    "        return ''.join([settings.bit_sep+str(b) for b in arr])\n",
    "    \n",
    "    bit_strs = []\n",
    "    for sign, digits,missing in zip(sign_arr, digits_arr, ismissing):\n",
    "        if not settings.fixed_length:\n",
    "            # remove leading zeros\n",
    "            nonzero_indices = np.where(digits != 0)[0]\n",
    "            if len(nonzero_indices) == 0:\n",
    "                digits = np.array([0])\n",
    "            else:\n",
    "                digits = digits[nonzero_indices[0]:]\n",
    "            # add a decimal point\n",
    "            prec = settings.prec\n",
    "            if len(settings.decimal_point):\n",
    "                digits = np.concatenate([digits[:-prec], np.array([settings.decimal_point]), digits[-prec:]])\n",
    "        digits = tokenize(digits)\n",
    "        sign_sep = plus_sign if sign==1 else minus_sign\n",
    "        if missing:\n",
    "            bit_strs.append(settings.missing_str)\n",
    "        else:\n",
    "            bit_strs.append(sign_sep + digits)\n",
    "    bit_str = settings.time_sep.join(bit_strs)\n",
    "    bit_str += settings.time_sep # otherwise there is ambiguity in number of digits in the last time step\n",
    "    return bit_str"
   ],
   "id": "f6a9d393273c650d",
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T13:10:42.267153Z",
     "start_time": "2024-01-25T13:10:42.232411Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "settings = best_hyper['settings']\n",
    "if isinstance(settings, dict):\n",
    "    settings = SerializerSettings(**settings)"
   ],
   "id": "4b4f14b1f0e20487",
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T13:10:44.111533Z",
     "start_time": "2024-01-25T13:10:44.072229Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 3 1 7 , 3 4 2 , 3 4 8 , 3 4 6 , 3 2 3 , 3 3 3 , 3 4 6 , 3 5 4 , 3 1 1 , 3 1 1 , 3 0 3 , 3 0 5 , 3 0 7 , 2 9 7 , 2 9 5 , 2 7 6 , 2 6 4 , 2 5 4 , 2 5 8 , 2 6 4 , 2 7 4 , 2 8 4 , 2 8 2 , 2 8 8 , 2 9 9 , 2 9 9 , 3 0 5 , 3 0 7 , 3 1 1 , 3 0 3 , 3 3 3 , 3 2 7 , 3 2 7 , 3 3 1 , 3 2 9 , 3 2 9 , 3 5 0 , 3 3 7 , 3 4 8 , 3 6 2 , 3 6 0 , 3 7 0 , 3 5 6 , 3 6 4 , 3 6 6 , 3 5 8 , 3 5 2 , 3 5 0 , 3 3 1 , 3 3 1 , 3 2 3 , 3 1 7 , 3 0 7 , 2 9 3 , 2 9 5 , 2 7 6 , 2 8 2 , 2 7 2 , 2 6 4 , 2 6 4 , 2 5 4 , 2 5 6 , 2 6 2 , 2 6 2 , 2 7 6 , 2 8 2 , 2 9 0 , 2 9 9 , 2 9 7 , 2 9 5 , 3 0 7 , 3 1 1 , 3 0 9 , 3 0 9 , 3 2 3 , 3 2 9 , 3 2 5 , 3 2 7 , 3 2 7 , 3 3 3 , 3 4 4 , 3 3 5 , 3 3 3 , 3 5 0 , 3 5 6 , 3 5 0 , 3 6 8 , 3 8 2 , 3 7 6 , 3 7 6 , 3 9 1 , 3 9 5 , 3 9 3 , 3 9 7 , 3 9 7 , 3 8 4 , 3 9 7 , 3 8 4 , 3 7 6 , 3 5 8 , 3 6 8 , 3 6 4 , 3 5 4 , 3 4 2 , 3 2 7 , 3 2 9 , 2 9 7 , 2 8 8 , 2 8 8 , 2 8 4 , 2 7 8 , 2 6 0 , 2 6 6 , 2 6 0 , 2 7 2 , 2 7 8 , 2 7 8 , 2 8 4 , 2 9 7 , 2 9 7 , 3 0 3 , 3 1 1 , 3 1 5 , 3 1 9 , 3 2 3 , 3 2 7 , 3 2 9 , 3 3 5 , 3 3 5 , 3 3 5 , 3 3 5 , 3 5 0 , 3 5 4 , 3 5 6 , 3 5 6 , 3 6 6 , 3 7 4 , 3 7 0 , 3 8 4 , 3 8 6 , 3 7 4 , 3 9 1 , 3 8 9 , 4 0 9 , 4 0 5 , 4 0 9 , 4 0 3 , 3 9 7 , 3 9 7 , 3 8 9 , 3 8 4 , 3 8 0 , 3 7 6 , 3 6 4 , 3 3 7 , 3 5 4 , 3 5 4 , 3 4 2 , 3 2 9 , 2 9 9 , 2 9 9 , 2 9 3 , 2 8 4 , 2 9 5 , 3 0 7 , 2 9 3 , 3 0 3 , 3 0 3 , 3 0 9 , 3 1 1 , 3 0 9 , 3 1 9 , 3 2 5 , 3 2 5 , 3 3 5 , 3 3 3 , 3 3 7 , 3 4 4 , 3 5 4 , 3 5 8 , 3 5 6 , 3 5 0 , 3 5 6 , 3 6 2 , 3 7 4 , 3 8 2 , 3 8 0 , 3 8 4 , 3 9 5 , 3 9 1 , 4 0 1 , 4 0 1 , 4 1 7 , 4 1 1 , 4 0 3 , 4 1 3 , 4 1 1 , 4 1 7 , 4 1 9 , 4 1 5 , 4 1 3 , 4 0 7 , 3 9 9 , 4 0 1 , 3 9 9 , 3 9 5 , 3 7 6 , 3 7 0 , 3 6 8 , 3 4 0 , 3 4 4 , 3 2 7 , 3 0 9 , 3 1 3 , 2 9 7 , 3 0 3 , 3 0 9 , 3 0 9 , 3 1 3 , 3 2 3 , 3 3 3 , 3 3 5 , 3 3 7 , 3 4 2 , 3 4 8 , 3 5 8 , 3 6 6 , 3 7 0 , 3 7 4 , 3 7 2 , 3 7 0 , 3 7 4 , 3 8 2 , 3 8 2 , 3 9 1 , 3 9 3 , 4 0 3 , 4 0 1 , 4 0 3 , 4 1 5 , 4 3 8 , 4 3 5 , 4 3 5 , 4 4 2 , 4 4 2 , 4 4 4 , 4 3 8 , 4 3 3 , 4 1 3 , 4 0 5 , 3 9 9 , 3 9 3 , 3 8 6 , 3 7 6 , 3 6 8 , 3 6 0 , 3 5 0 , 3 3 7 , 3 2 3 , 3 3 1 , 3 1 3 , 3 1 5 , 3 1 3 , 3 1 9 , 3 0 7 , 3 1 7 , 3 2 1 , 3 2 7 , 3 3 1 , 3 3 7 , 3 4 6 , 3 5 6 , 3 6 0 , 3 6 6 , 3 7 0 , 3 7 6 , 3 8 4 , 3 9 3 , 4 3 8 , 4 3 8 , 4 2 7 , 4 1 9 , 3 9 5 , 4 0 1 , 3 9 7 , 3 7 8 , 3 6 8 , 3 6 0 , 3 5 8 , 3 4 4 , 3 2 5 , 3 0 5 , 3 3 5 , 3 3 3 , 3 2 5 , 3 3 1 , 3 3 5 , 3 4 8 , 3 5 0 , 3 4 8 , 3 4 6 , 3 5 8 , 3 6 4 , 3 6 6 , 3 7 4 , 3 7 4 , 3 7 6 , 3 7 8 , 3 7 8 , 3 9 1 , 3 9 9 , 4 0 1 , 3 9 9 , 4 1 1 , 4 1 3 , 4 1 7 , 4 1 5 , 4 0 5 , 4 2 5 , 4 3 5 , 4 4 2 , 4 4 0 , 4 3 3 , 4 4 6 , 4 4 2 , 4 3 5 , 4 2 9 , 4 4 2 , 4 3 3 , 4 3 1 , 4 3 1 , 4 3 5 , 4 3 5 , 4 3 3 , 4 3 1 , 4 0 5 , 3 8 4 , 3 8 4 , 3 5 6 , 3 7 2 , 3 7 0 , 3 6 2 , 3 5 6 , 3 6 0 , 3 3 1 , 3 2 7 , 3 4 0 , 3 5 2 , 3 4 6 , 3 4 8 , 3 6 2 , 3 8 0 , 3 7 4 , 3 7 8 , 3 7 6 , 3 8 2 , 3 8 2 , 3 9 1 , 3 8 9 , 4 0 5 , 4 0 9 , 4 1 7 , 4 1 9 , 4 2 1 , 4 3 1 , 4 2 9 , 4 3 3 , 4 4 0 , 4 4 0 , 4 4 8 , 4 5 4 , 4 6 8 , 4 7 0 , 4 7 4 , 4 7 6 , 4 6 8 , 4 7 8 , 4 8 0 , 4 7 2 , 4 8 4 , 4 7 8 , 4 7 4 , 4 7 2 , 4 6 4 , 4 5 4 , 4 5 6 , 4 2 3 , 4 1 3 , 3 7 8 , 3 8 9 , 3 9 5 , 3 6 0 , 3 6 4 , 3 6 2 , 3 5 4 , 3 5 4 , 3 6 0 , 3 6 8 , 3 6 2 , 3 8 6 , 3 9 7 , 4 0 1 , 4 1 3 , 4 1 3 , 4 1 9 , 4 2 3 , 4 2 3 , 4 3 5 , 4 5 6 , 4 4 0 , 4 4 2 , 4 5 4 , 4 5 0 , 4 5 6 , 4 5 0 , 4 6 4 , 4 6 2 , 4 6 0 , 4 8 2 , 4 8 7 , 4 9 1 , 5 0 1 , 5 0 3 , 4 9 3 , 4 9 9 , 4 9 7 , 4 9 7 , 4 9 1 , 4 6 4 , 4 6 8 , 4 5 4 , 4 5 4 , 4 4 6 , 4 4 6 , 4 3 8 , 4 2 9 , 4 2 5 , 4 0 5 , 3 9 7 , 3 9 7 , 3 8 4 , 3 8 2 , 3 7 6 , 3 7 2 , 3 7 2 , 3 9 3 , 3 8 4 , 3 9 3 , 3 9 7 , 4 0 3 , 4 1 5 , 4 2 7 , 4 2 5 , 4 3 3 , 4 4 2 , 4 3 5 , 4 4 4 , 4 4 6 , 4 4 8 , 4 4 8 , 4 5 4 , 4 5 0 , 4 6 0 , 4 6 6 , 4 6 0 , 4 6 0 , 4 7 4 , 4 7 4 , 4 8 2 , 4 9 3 , 4 9 3 , 4 9 9 , 4 9 5 , 5 0 7 , 5 1 1 , 4 9 9 , 5 0 9 , 5 1 5 , 5 1 1 , 5 1 3 , 5 0 9 , 4 9 7 , 4 9 1 , 4 9 3 , 4 8 0 , 4 7 6 , 4 6 6 , 4 4 6 , 4 4 2 , 4 3 8 , 4 3 1 , 4 2 5 , 4 0 5 , 4 1 9 , 3 9 1 , 3 9 3 , 4 0 7 , 4 0 7 , 4 0 1 , 3 9 5 , 4 1 1 , 4 1 3 , 4 2 5 , 4 3 1 , 4 3 8 , 4 4 6 , 4 5 6 , 4 6 4 , 4 6 0 , 4 6 4 , 4 7 8 , 4 8 4 , 4 8 0 , 4 8 0 , 4 7 6 , 4 8 4 , 4 9 5 , 5 0 1 , 5 0 9 , 5 1 3 , 5 1 7 , 5 1 5 , 5 2 3 , 5 4 2 , 5 2 9 , 5 2 9 , 5 5 0 , 5 5 6 , 5 3 6 , 5 3 8 , 5 4 8 , 5 2 9 , 5 3 4 , 5 3 4 , 5 2 5 , 5 2 1 , 5 1 9 , 5 1 3 , 5 0 7 , 4 8 9 , 4 8 9 , 4 6 0 , 4 4 8 , 4 6 0 , 4 4 2 , 4 5 2 , 4 5 4 , 4 3 5 , 4 2 7 , 4 3 3 , 4 3 8 , 4 3 5 , 4 4 2 , 4 5 0 , 4 5 2 , 4 6 0 , 4 6 8 , 4 7 6 , 4 7 6 , 4 8 2 , 4 8 9 , 4 9 3 , 5 0 7 , 4 9 9 , 4 9 5 , 5 0 9 , 5 1 3 , 5 1 9 , 5 2 5 , 5 2 1 , 5 3 6 , 5 3 6 , 5 5 0 , 5 3 8 , 5 6 4 , 5 5 6 , 5 5 6 , 5 7 0 , 5 5 8 , 5 5 0 , 5 6 0 , 5 6 6 , 5 5 8 , 5 5 0 , 5 5 6 , 5 5 4 , 5 4 4 , 5 4 4 , 5 2 3 , 5 2 3 , 5 1 1 , 5 0 3 , 5 0 3 , 4 9 5 , 4 9 5 , 4 6 4 , 4 5 6 , 4 6 8 , 4 6 0 , 4 6 0 , 4 6 2 , 4 6 8 , 4 5 6 , 4 5 8 , 4 6 0 , 4 7 0 , 4 7 2 , 4 8 2 , 4 9 3 , 4 9 3 , 4 9 9 , 5 0 3 , 5 0 9 , 5 1 3 , 5 1 5 , 5 1 7 , 5 3 4 , 5 3 1 , 5 2 9 , 5 2 7 , 5 3 4 , 5 4 0 , 5 4 2 , 5 4 6 , 5 4 0 , 5 4 8 , 5 4 8 , 5 4 2 , 5 5 4 , 5 7 0 , 5 6 4 , 5 8 0 , 5 8 5 , 5 7 8 , 5 7 6 , 5 7 0 , 5 7 6 , 5 6 2 , 5 7 0 , 5 5 8 , 5 5 6 , 5 5 0 , 5 2 3 , 5 3 4 , 5 2 1 , 5 1 1 , 5 0 5 , 4 7 8 , 4 7 0 , 4 6 8 , 4 6 2 , 4 6 4 , 4 6 4 , 4 5 6 , 4 6 8 , 4 7 0 , 4 8 7 , 4 8 4 , 4 8 9 , 4 9 9 , 5 0 9 , 5 0 5 , 5 1 7 , 5 2 3 , 5 2 5 , 5 3 1 , 5 3 1 , 5 3 1 , 5 3 1 , 5 4 4 , 5 4 8 , 5 5 8 , 5 5 6 , 5 4 8 , 5 5 0 , 5 4 2 , 5 5 4 , 5 7 2 , 5 7 8 , 5 8 9 , 5 9 7 , 6 0 3 , 6 0 1 , 6 0 1 , 5 9 5 , 6 0 3 , 6 0 5 , 5 9 5 , 5 8 3 , 5 8 0 , 5 7 0 , 5 7 2 , 5 6 6 , 5 5 4 , 5 6 2 , 5 5 0 , 5 3 8 , 5 3 1 , 5 2 9 , 4 9 9 , 5 0 7 , 5 1 3 , 4 9 5 , 4 8 2 , 4 8 2 , 4 9 5 , 5 0 9 , 5 0 1 , 5 1 5 , 5 2 5 , 5 2 1 , 5 2 7 , 5 3 8 , 5 3 8 , 5 4 2 , 5 5 2 , 5 5 8 , 5 6 4 , 5 6 8 , 5 6 8 , 5 7 2 , 5 7 6 , 5 8 3 , 5 9 1 , 5 9 3 , 5 9 5 , 5 9 9 , 6 0 3 , 6 1 1 , 6 1 7 , 6 1 3 , 6 2 5 , 6 2 3 , 6 4 0 , 6 4 4 , 6 4 6 , 6 4 8 , 6 5 4 , 6 5 2 , 6 4 6 , 6 5 2 , 6 4 2 , 6 3 4 , 6 2 9 , 6 3 2 , 6 2 1 , 6 0 1 , 6 0 3 , 6 0 1 , 5 9 1 , 5 8 7 , 5 7 0 , 5 6 8 , 5 5 2 , 5 5 6 , 5 4 2 , 5 3 1 , 5 4 0 , 5 4 8 , 5 4 8 , 5 4 2 , 5 5 0 , 5 6 0 , 5 6 4 , 5 7 0 , 5 8 0 , 5 7 4 , 5 7 2 , 5 6 4 , 5 7 4 , 5 7 8 , 5 8 5 , 5 8 9 , 5 9 7 , 6 1 1 , 6 1 7 , 6 1 3 , 6 1 3 , 6 1 5 , 6 2 5 , 6 4 4 , 6 4 2 , 6 3 2 , 6 5 0 , 6 4 4 , 6 6 0 , 6 6 4 , 6 6 0 , 6 6 2 , 6 6 6 , 6 5 8 , 6 6 0 , 6 4 2 , 6 4 2 , 6 4 6 , 6 3 6 , 6 3 6 , 6 2 5 , 6 0 9 , 6 2 1 , 6 0 1 , 5 9 9 , 5 8 5 , 5 7 8 , 5 6 2 , 5 6 0 , 5 4 6 , 5 3 8 , 5 4 6 , 5 4 6 , 5 4 0 , 5 5 0 , 5 5 4 , 5 5 8 , 5 6 0 , 5 7 6 , 5 7 2 , 5 7 4 , 5 9 1 , 5 9 5 , 5 9 7 , 5 9 5 , 5 9 9 , 5 9 7 , 6 0 5 , 6 2 3 , 6 2 3 , 6 2 9 , 6 2 1 , 6 3 6 , 6 3 8 , 6 3 4 , 6 4 0 , 6 4 6 , 6 5 2 , 6 6 2 , 6 7 2 , 6 7 2 , 6 6 4 , 6 8 1 , 6 8 1 , 6 7 6 , 6 7 6 , 6 8 5 , 6 7 8 , 6 6 8 , 6 7 0 , 6 6 4 , 6 5 6 , 6 4 2 , 6 2 1 , 6 3 2 , 6 1 7 , 6 1 5 , 6 0 7 , 5 8 7 , 5 7 6 , 5 8 9 , 5 7 0 , 5 6 0 , 5 6 4 , 5 6 0 , 5 6 0 , 5 7 0 , 5 7 6 , 5 8 7 , 5 8 5 , 5 8 3 , 5 9 1 , 6 0 3 , 6 0 7 , 6 1 1 , 6 2 3 , 6 2 5 , 6 3 2 , 6 3 2 , 6 3 6 , 6 3 8 , 6 4 6 , 6 4 4 , 6 5 2 , 6 6 6 , 6 5 0 , 6 5 8 , 6 7 4 , 6 6 4 , 6 8 9 , 6 9 7 , 6 8 7 , 6 9 1 , 6 9 3 , 6 9 7 , 6 8 9 , 6 9 5 , 7 1 1 , 6 9 9 , 6 8 9 , 6 9 5 , 6 8 9 , 6 7 4 , 6 7 0 , 6 5 8 , 6 5 0 , 6 4 4 , 6 3 6 , 6 1 3 , 6 1 3 , 6 0 1 , 5 9 5 , 6 0 1 , 5 8 7 , 5 6 8 , 5 7 6 , 5 8 0 , 5 9 3 , 5 8 3 , 5 8 0 , 5 9 7 , 6 0 9 , 6 1 1 , 6 1 5 , 6 2 3 , 6 2 7 , 6 4 0 , 6 4 6 , 6 5 2 , 6 5 0 , 6 6 4 , 6 6 6 , 6 6 6 , 6 7 0 , 6 6 8 , 6 7 0 , 6 7 4 , 6 8 5 , 6 9 5 , 7 0 5 , 7 0 3 , 7 1 3 , 7 2 1 , 7 2 3 , 7 2 5 , 7 3 8 , 7 4 0 , 7 3 2 , 7 4 0 , 7 3 8 , 7 3 2 , 7 3 0 , 7 2 5 , 7 2 3 , 7 1 3 , 7 0 5 , 7 0 5 , 6 9 5 , 6 7 6 , 6 6 2 , 6 6 0 , 6 5 8 , 6 5 8 , 6 4 4 , 6 2 5 , 6 4 4 , 6 1 9 , 6 0 9 , 6 1 9 , 6 3 2 , 6 3 2 , 6 3 6 , 6 4 4 , 6 4 2 , 6 5 2 , 6 5 8 , 6 6 6 , 6 7 2 , 6 7 8 , 6 8 7 , 6 9 5 , 6 8 7 , 6 9 5 , 7 1 1 , 7 2 1 , 7 0 3 , 7 0 5 , 7 1 5 , 7 1 7 , 7 2 7 , 7 2 5 , 7 4 0 , 7 5 0 , 7 4 4 , 7 6 2 , 7 6 2 , 7 5 2 , 7 6 4 , 7 6 4 , 7 6 6 , 7 6 0 , 7 6 2 , 7 7 2 , 7 6 8 , 7 6 0 , 7 5 0 , 7 5 6 , 7 3 8 , 7 3 8 , 7 2 1 , 7 1 5 , 7 0 5 , 6 9 9 , 6 9 1 , 6 8 9 , 6 7 8 , 6 5 8 , 6 4 4 , 6 4 8 , 6 5 6 , 6 4 4 , 6 5 0 , 6 6 2 , 6 6 4 , 6 7 2 , 6 7 8 , 6 7 8 , 6 8 7 , 6 9 3 , 6 9 9 , 7 0 5 , 7 0 5 , 7 0 9 , 7 0 9 , 7 2 1 , 7 4 0 , 7 4 2 , 7 4 2 , 7 3 4 , 7 3 8 , 7 3 8 , 7 4 6 , 7 5 8 , 7 5 2 , 7 8 5 , 7 8 1 , 7 6 6 , 7 7 7 , 7 8 9 , 7 9 7 , 7 9 1 , 7 8 1 , 8 0 1 , 7 9 7 , 8 0 3 , 7 9 5 , 7 8 3 , 7 8 3 , 7 8 5 , 7 6 8 , 7 6 0 , 7 5 0 , 7 4 0 , 7 4 4 , 7 3 4 , 7 2 5 , 6 9 3 , 6 9 1 , 6 8 3 , 6 8 7 , 6 6 6 , 6 8 5 , 6 8 5 , 6 8 1 , 6 7 6 , 6 8 5 , 6 9 7 , 6 9 9 , 7 1 3 , 7 1 5 , 7 2 1 , 7 3 4 , 7 3 8 , 7 4 0 , 7 5 2 , 7 5 6 , 7 5 2 , 7 7 0 , 7 7 2 , 7 6 4 , 7 6 6 , 7 7 7 , 7 6 8 , 7 9 1 , 7 9 5 , 8 0 5 , 8 1 5 , 8 2 6 , 8 1 3 , 8 2 3 , 8 1 9 , 8 2 6 , 8 3 6 , 8 3 2 , 8 3 2 , 8 2 3 , 8 4 0 , 8 3 2 , 8 3 2 , 8 2 1 , 8 1 3 , 8 1 3 , 7 9 9 , 7 7 4 , 7 8 3 , 7 6 2 , 7 5 8 , 7 5 8 , 7 5 8 , 7 4 4 , 7 3 6 , 7 1 7 , 7 0 7 , 7 2 3 , 7 1 9 , 7 1 9 , 7 2 5 , 7 3 2 , 7 3 6 , 7 4 2 , 7 4 6 , 7 5 0 , 7 5 2 , 7 5 8 , 7 6 6 , 7 7 0 , 7 7 9 , 7 8 3 , 7 8 7 , 7 9 1 , 7 9 1 , 7 9 5 , 8 1 5 , 8 0 5 , 8 0 9 , 8 2 8 , 8 1 9 , 8 2 6 , 8 4 2 , 8 4 8 , 8 5 4 , 8 5 4 , 8 6 0 , 8 5 2 , 8 6 4 , 8 6 6 , 8 6 2 , 8 6 0 , 8 6 0 , 8 5 8 , 8 5 6 , 8 4 2 , 8 3 8 , 8 2 6 , 8 2 1 , 7 9 9 , 8 0 9 , 7 9 5 , 7 8 3 , 7 7 2 , 7 5 4 , 7 5 8 , 7 4 8 , 7 4 4 , 7 3 8 , 7 2 1 , 7 3 0 , 7 3 6 , 7 4 6 , 7 4 8 , 7 5 4 , 7 6 0 , 7 6 6 , 7 7 4 , 7 9 1 , 7 8 9 , 7 9 3 , 7 9 7 , 8 0 9 , 8 0 9 , 8 1 1 , 8 1 9 , 8 2 8 , 8 3 0 , 8 4 4 , 8 2 8 , 8 2 8 , 8 4 8 , 8 5 8 , 8 5 8 , 8 6 0 , 8 6 2 , 8 6 4 , 8 7 2 , 8 7 7 , 8 9 1 , 8 8 3 , 8 7 9 , 8 9 1 , 8 8 9 , 8 8 9 , 8 7 5 , 8 7 7 , 8 7 5 , 8 6 4 , 8 5 6 , 8 4 6 , 8 4 6 , 8 4 2 , 8 3 2 , 8 1 5 , 8 0 5 , 7 9 9 , 7 7 0 , 7 8 1 , 7 7 7 , 7 6 0 , 7 4 2 , 7 5 0 , 7 6 4 , 7 5 6 , 7 6 2 , 7 7 9 , 7 7 2 , 7 8 9 , 7 9 9 , 8 0 1 , 8 0 1 , 8 1 3 , 8 1 9 , 8 2 1 , 8 2 3 , 8 3 4 , 8 3 6 , 8 3 0 , 8 4 0 , 8 4 6 , 8 6 0 , 8 5 6 , 8 6 2 , 8 5 2 , 8 5 6 , 8 8 7 , 8 8 3 , 8 8 7 , 9 0 3 , 9 0 7 , 9 1 3 , 9 1 5 , 9 1 5 , 9 2 1 , 9 2 4 , 9 2 1 , 9 1 9 , 9 1 9 , 9 0 7 , 9 0 5 , 9 0 1 , 8 9 7 , 8 8 1 , 8 7 9 , 8 5 8 , 8 6 6 , 8 4 0 , 8 4 8 , 8 4 2 , 8 0 3 , 8 0 3 , 8 0 1 , 8 0 3 , 8 0 1 , 7 9 9 , 8 0 7 , 8 0 9 , 8 1 1 , 8 2 1 , 8 2 6 , 8 2 8 , 8 4 0 , 8 4 2 , 8 6 2 , 8 7 2 , 8 7 9 , 8 7 5 , 8 8 1 , 8 7 5 , 8 7 7 , 8 8 9 , 8 9 3 , 8 9 7 , 8 9 3 , 8 9 9 , 9 0 3 , 9 0 5 , 9 1 5 , 9 1 9 , 9 5 6 , 9 5 6 , 9 6 2 , 9 5 4 , 9 4 8 , 9 4 8 , 9 4 8 , 9 4 4 , 9 3 4 , 9 3 2 , 9 2 4 , 9 1 5 , 9 1 1 , 8 9 5 , 8 8 7 , 8 8 9 , 8 6 8 , 8 4 6 , 8 3 8 , 8 1 7 , 8 3 2 , 8 3 2 , 8 2 1 , 8 2 8 , 8 3 2 , 8 4 4 , 8 3 8 , 8 4 6 , 8 5 8 , 8 6 8 , 8 8 1 , 8 7 9 , 8 8 5 , 8 9 1 , 8 9 7 , 8 9 7 , 9 0 1 , 9 0 7 , 9 0 7 , 9 0 7 , 9 2 6 , 9 1 7 , 9 2 4 , 9 3 4 , 9 4 2 , 9 5 0 , 9 5 8 , 9 6 2 , 9 7 3 , 9 6 8 , 9 6 8 , 9 7 9 , 9 8 5 , 9 8 5 , 9 9 5 , 9 9 1 , 9 7 1 , 9 8 9 , 9 7 7 , 9 7 3 , 9 6 6 , 9 5 6 , 9 4 6 , 9 4 4 , 9 3 6 , 9 2 1 , 9 0 1 , 8 9 7 , 8 9 3 , 8 8 1 , 8 9 1 , 8 7 2 , 8 5 4 , 8 4 8 , 8 5 4 , 8 5 6 , 8 6 8 , 8 7 0 , 8 7 2 , 8 8 1 , 8 9 1 , 8 9 9 , 9 1 3 , 9 1 3 , 9 1 9 , 9 0 9 , 9 3 4 , 9 3 6 , 9 2 8 , 9 3 2 , 9 3 6 , 9 3 2 , 9 4 4 , 9 5 0 , 9 5 2 , 9 4 8 , 9 4 0 , 9 5 2 , 9 9 1 , 9 8 5 , 9 9 3 , 9 9 7 , 9 9 5 , 1 0 1 3 , 1 0 0 7 , 1 0 1 1 , 1 0 1 3 , 1 0 1 1 , 1 0 1 1 , 1 0 0 3 , 9 9 9 , 9 9 7 , 9 8 7 , 9 8 1 , 9 6 2 , 9 6 0 , 9 5 6 , 9 4 0 , 9 3 2 , 9 1 7 , 9 1 9 , 9 1 1 , 9 0 7 , 9 1 3 , 8 9 5 , 8 9 7 , 8 8 5 , 8 8 9 , 8 8 5 , 8 9 7 , 9 0 9 , 9 1 3 , 9 1 9 , 9 2 1 , 9 3 6 , 9 4 6 , 9 4 2 , 9 4 6 , 9 4 8 , 9 6 0 , 9 7 5 , 9 7 3 , 9 6 6 , 9 6 8 , 9 6 6 , 9 7 3 , 9 7 9 , 9 9 7 , 9 8 5 , 9 9 3 , 1 0 0 3 , 1 0 1 3 , 1 0 2 6 , 1 0 1 3 , 1 0 3 2 , 1 0 3 6 , 1 0 3 8 , 1 0 5 0 , 1 0 4 4 , 1 0 4 8 , 1 0 4 4 , 1 0 4 2 , 1 0 3 2 , 1 0 3 0 , 1 0 2 8 , 1 0 0 3 , 1 0 0 5 , 9 8 5 , 9 9 9 , 9 8 9 , 9 7 1 , 9 8 1 , 9 6 8 , 9 4 2 , 9 4 8 , 9 4 0 , 9 3 2 , 9 2 4 , 9 2 1 , 9 3 4 , 9 3 8 , 9 4 4 , 9 4 6 , 9 5 4 , 9 6 0 , 9 7 1 , 9 8 3 , 9 8 1 , 9 8 5 , 9 9 1 , 9 9 3 , 1 0 0 3 , 1 0 1 3 , 1 0 1 3 , 1 0 2 4 , 1 0 3 4 , 1 0 4 6 , 1 0 3 6 , 1 0 4 0 , 1 0 6 0 , 1 0 6 6 , 1 0 4 6 , 1 0 4 4 , 1 0 5 4 , 1 0 7 3 , 1 0 8 1 , 1 0 7 3 , 1 0 9 1 , 1 0 9 5 , 1 0 8 5 , 1 0 9 7 , 1 1 0 1 , 1 0 9 5 , 1 0 9 3 , 1 0 9 5 , 1 0 8 3 , 1 0 7 3 , 1 0 7 1 , 1 0 6 0 , 1 0 6 2 , 1 0 4 8 , 1 0 3 2 , 1 0 2 8 , 1 0 1 5 , 1 0 1 7 , 1 0 0 1 , 9 9 5 , 9 8 3 , 9 8 7 , 9 7 1 , 9 8 5 , 9 8 5 , 9 8 1 , 9 9 7 , 9 9 3 , 1 0 0 3 , 1 0 0 5 , 1 0 1 1 , 1 0 1 7 , 1 0 2 0 , 1 0 3 0 , 1 0 4 2 , 1 0 3 6 , 1 0 5 8 , 1 0 6 4 , 1 0 6 9 , 1 0 6 0 , 1 0 7 1 , 1 0 6 6 , 1 0 6 2 , 1 0 7 5 , 1 0 7 9 , 1 0 7 3 , 1 0 7 9 ,']"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 50
    }
   ],
   "source": [
    "input_strs = [serialize_arr(scaled_input_arr, settings) for scaled_input_arr in transformed_input_arrs]\n",
    "input_strs"
   ],
   "id": "1d5fe5e1e7489d4b",
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T10:02:50.397889Z",
     "start_time": "2024-01-26T10:02:47.613368Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "from transformers import (\n",
    "    LlamaForCausalLM, \n",
    "    LlamaTokenizer, \n",
    ")\n",
    "\n",
    "def get_tokenizer(model):\n",
    "    name_parts = model.split(\"-\")\n",
    "    model_size = name_parts[0]\n",
    "    chat = len(name_parts) > 1\n",
    "    assert model_size in [\"7b\", \"13b\", \"70b\"]\n",
    "    \n",
    "    chat = \"chat-\" if chat else \"\"\n",
    "\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(\n",
    "        f\"meta-llama/Llama-2-{model_size.lower()}-{chat}hf\",\n",
    "        use_fast=False,\n",
    "    )\n",
    "\n",
    "    special_tokens_dict = dict()\n",
    "    if tokenizer.eos_token is None:\n",
    "        special_tokens_dict[\"eos_token\"] = DEFAULT_EOS_TOKEN\n",
    "    if tokenizer.bos_token is None:\n",
    "        special_tokens_dict[\"bos_token\"] = DEFAULT_BOS_TOKEN\n",
    "    if tokenizer.unk_token is None:\n",
    "        special_tokens_dict[\"unk_token\"] = DEFAULT_UNK_TOKEN\n",
    "\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "def tokenize_fn(str, model):\n",
    "    tokenizer = get_tokenizer(model)\n",
    "    return tokenizer(str)\n",
    "\n",
    "def truncate_input(input_arr, input_str, settings, steps):\n",
    "    \"\"\"\n",
    "    Truncate inputs to the maximum context length for a given model.\n",
    "    \"\"\"\n",
    "    tokenization_fn = partial(tokenize_fn, model='7b')\n",
    "    context_length = 4096\n",
    "    input_str_chuncks = input_str.split(settings.time_sep)\n",
    "    for i in range(len(input_str_chuncks) - 1):\n",
    "        truncated_input_str = settings.time_sep.join(input_str_chuncks[i:])\n",
    "        # add separator if not already present\n",
    "        if not truncated_input_str.endswith(settings.time_sep):\n",
    "            truncated_input_str += settings.time_sep\n",
    "        input_tokens = tokenization_fn(truncated_input_str)\n",
    "        num_input_tokens = len(input_tokens)\n",
    "        avg_token_length = num_input_tokens / (len(input_str_chuncks) - i)\n",
    "        STEP_MULTIPLIER = 1.2\n",
    "        num_output_tokens = avg_token_length * steps * STEP_MULTIPLIER\n",
    "        if num_input_tokens + num_output_tokens <= context_length:\n",
    "            truncated_input_arr = input_arr[i:]\n",
    "            break\n",
    "    if i > 0:\n",
    "        print(f'Warning: Truncated input from {len(input_arr)} to {len(truncated_input_arr)}')\n",
    "    return truncated_input_arr, truncated_input_str"
   ],
   "id": "a49b60d0907ed9fe",
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T10:03:35.771992Z",
     "start_time": "2024-01-26T10:03:29.335645Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31cee38bc5fb4a68808c6b3d9c845cd4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "063bc009031b44dc99ddaf0d54174a24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2097493f95b49c5a0d84bb95c24da1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b54f1602359492698375c07531e3e8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_arrs, input_strs = zip(*[truncate_input(input_array, input_str, settings, len(test[0])) for input_array, input_str in zip(input_arrs, input_strs)])"
   ],
   "id": "9fba2f33c011126a",
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T10:03:40.976081Z",
     "start_time": "2024-01-26T10:03:40.926Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([316.1, 317.3, 317.6, ..., 353.4, 353.1, 353.4]),)"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 57
    }
   ],
   "source": [
    "input_arrs"
   ],
   "id": "c2be76a32386658c",
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T10:03:46.252510Z",
     "start_time": "2024-01-26T10:03:46.192798Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' 3 1 7 , 3 4 2 , 3 4 8 , 3 4 6 , 3 2 3 , 3 3 3 , 3 4 6 , 3 5 4 , 3 1 1 , 3 1 1 , 3 0 3 , 3 0 5 , 3 0 7 , 2 9 7 , 2 9 5 , 2 7 6 , 2 6 4 , 2 5 4 , 2 5 8 , 2 6 4 , 2 7 4 , 2 8 4 , 2 8 2 , 2 8 8 , 2 9 9 , 2 9 9 , 3 0 5 , 3 0 7 , 3 1 1 , 3 0 3 , 3 3 3 , 3 2 7 , 3 2 7 , 3 3 1 , 3 2 9 , 3 2 9 , 3 5 0 , 3 3 7 , 3 4 8 , 3 6 2 , 3 6 0 , 3 7 0 , 3 5 6 , 3 6 4 , 3 6 6 , 3 5 8 , 3 5 2 , 3 5 0 , 3 3 1 , 3 3 1 , 3 2 3 , 3 1 7 , 3 0 7 , 2 9 3 , 2 9 5 , 2 7 6 , 2 8 2 , 2 7 2 , 2 6 4 , 2 6 4 , 2 5 4 , 2 5 6 , 2 6 2 , 2 6 2 , 2 7 6 , 2 8 2 , 2 9 0 , 2 9 9 , 2 9 7 , 2 9 5 , 3 0 7 , 3 1 1 , 3 0 9 , 3 0 9 , 3 2 3 , 3 2 9 , 3 2 5 , 3 2 7 , 3 2 7 , 3 3 3 , 3 4 4 , 3 3 5 , 3 3 3 , 3 5 0 , 3 5 6 , 3 5 0 , 3 6 8 , 3 8 2 , 3 7 6 , 3 7 6 , 3 9 1 , 3 9 5 , 3 9 3 , 3 9 7 , 3 9 7 , 3 8 4 , 3 9 7 , 3 8 4 , 3 7 6 , 3 5 8 , 3 6 8 , 3 6 4 , 3 5 4 , 3 4 2 , 3 2 7 , 3 2 9 , 2 9 7 , 2 8 8 , 2 8 8 , 2 8 4 , 2 7 8 , 2 6 0 , 2 6 6 , 2 6 0 , 2 7 2 , 2 7 8 , 2 7 8 , 2 8 4 , 2 9 7 , 2 9 7 , 3 0 3 , 3 1 1 , 3 1 5 , 3 1 9 , 3 2 3 , 3 2 7 , 3 2 9 , 3 3 5 , 3 3 5 , 3 3 5 , 3 3 5 , 3 5 0 , 3 5 4 , 3 5 6 , 3 5 6 , 3 6 6 , 3 7 4 , 3 7 0 , 3 8 4 , 3 8 6 , 3 7 4 , 3 9 1 , 3 8 9 , 4 0 9 , 4 0 5 , 4 0 9 , 4 0 3 , 3 9 7 , 3 9 7 , 3 8 9 , 3 8 4 , 3 8 0 , 3 7 6 , 3 6 4 , 3 3 7 , 3 5 4 , 3 5 4 , 3 4 2 , 3 2 9 , 2 9 9 , 2 9 9 , 2 9 3 , 2 8 4 , 2 9 5 , 3 0 7 , 2 9 3 , 3 0 3 , 3 0 3 , 3 0 9 , 3 1 1 , 3 0 9 , 3 1 9 , 3 2 5 , 3 2 5 , 3 3 5 , 3 3 3 , 3 3 7 , 3 4 4 , 3 5 4 , 3 5 8 , 3 5 6 , 3 5 0 , 3 5 6 , 3 6 2 , 3 7 4 , 3 8 2 , 3 8 0 , 3 8 4 , 3 9 5 , 3 9 1 , 4 0 1 , 4 0 1 , 4 1 7 , 4 1 1 , 4 0 3 , 4 1 3 , 4 1 1 , 4 1 7 , 4 1 9 , 4 1 5 , 4 1 3 , 4 0 7 , 3 9 9 , 4 0 1 , 3 9 9 , 3 9 5 , 3 7 6 , 3 7 0 , 3 6 8 , 3 4 0 , 3 4 4 , 3 2 7 , 3 0 9 , 3 1 3 , 2 9 7 , 3 0 3 , 3 0 9 , 3 0 9 , 3 1 3 , 3 2 3 , 3 3 3 , 3 3 5 , 3 3 7 , 3 4 2 , 3 4 8 , 3 5 8 , 3 6 6 , 3 7 0 , 3 7 4 , 3 7 2 , 3 7 0 , 3 7 4 , 3 8 2 , 3 8 2 , 3 9 1 , 3 9 3 , 4 0 3 , 4 0 1 , 4 0 3 , 4 1 5 , 4 3 8 , 4 3 5 , 4 3 5 , 4 4 2 , 4 4 2 , 4 4 4 , 4 3 8 , 4 3 3 , 4 1 3 , 4 0 5 , 3 9 9 , 3 9 3 , 3 8 6 , 3 7 6 , 3 6 8 , 3 6 0 , 3 5 0 , 3 3 7 , 3 2 3 , 3 3 1 , 3 1 3 , 3 1 5 , 3 1 3 , 3 1 9 , 3 0 7 , 3 1 7 , 3 2 1 , 3 2 7 , 3 3 1 , 3 3 7 , 3 4 6 , 3 5 6 , 3 6 0 , 3 6 6 , 3 7 0 , 3 7 6 , 3 8 4 , 3 9 3 , 4 3 8 , 4 3 8 , 4 2 7 , 4 1 9 , 3 9 5 , 4 0 1 , 3 9 7 , 3 7 8 , 3 6 8 , 3 6 0 , 3 5 8 , 3 4 4 , 3 2 5 , 3 0 5 , 3 3 5 , 3 3 3 , 3 2 5 , 3 3 1 , 3 3 5 , 3 4 8 , 3 5 0 , 3 4 8 , 3 4 6 , 3 5 8 , 3 6 4 , 3 6 6 , 3 7 4 , 3 7 4 , 3 7 6 , 3 7 8 , 3 7 8 , 3 9 1 , 3 9 9 , 4 0 1 , 3 9 9 , 4 1 1 , 4 1 3 , 4 1 7 , 4 1 5 , 4 0 5 , 4 2 5 , 4 3 5 , 4 4 2 , 4 4 0 , 4 3 3 , 4 4 6 , 4 4 2 , 4 3 5 , 4 2 9 , 4 4 2 , 4 3 3 , 4 3 1 , 4 3 1 , 4 3 5 , 4 3 5 , 4 3 3 , 4 3 1 , 4 0 5 , 3 8 4 , 3 8 4 , 3 5 6 , 3 7 2 , 3 7 0 , 3 6 2 , 3 5 6 , 3 6 0 , 3 3 1 , 3 2 7 , 3 4 0 , 3 5 2 , 3 4 6 , 3 4 8 , 3 6 2 , 3 8 0 , 3 7 4 , 3 7 8 , 3 7 6 , 3 8 2 , 3 8 2 , 3 9 1 , 3 8 9 , 4 0 5 , 4 0 9 , 4 1 7 , 4 1 9 , 4 2 1 , 4 3 1 , 4 2 9 , 4 3 3 , 4 4 0 , 4 4 0 , 4 4 8 , 4 5 4 , 4 6 8 , 4 7 0 , 4 7 4 , 4 7 6 , 4 6 8 , 4 7 8 , 4 8 0 , 4 7 2 , 4 8 4 , 4 7 8 , 4 7 4 , 4 7 2 , 4 6 4 , 4 5 4 , 4 5 6 , 4 2 3 , 4 1 3 , 3 7 8 , 3 8 9 , 3 9 5 , 3 6 0 , 3 6 4 , 3 6 2 , 3 5 4 , 3 5 4 , 3 6 0 , 3 6 8 , 3 6 2 , 3 8 6 , 3 9 7 , 4 0 1 , 4 1 3 , 4 1 3 , 4 1 9 , 4 2 3 , 4 2 3 , 4 3 5 , 4 5 6 , 4 4 0 , 4 4 2 , 4 5 4 , 4 5 0 , 4 5 6 , 4 5 0 , 4 6 4 , 4 6 2 , 4 6 0 , 4 8 2 , 4 8 7 , 4 9 1 , 5 0 1 , 5 0 3 , 4 9 3 , 4 9 9 , 4 9 7 , 4 9 7 , 4 9 1 , 4 6 4 , 4 6 8 , 4 5 4 , 4 5 4 , 4 4 6 , 4 4 6 , 4 3 8 , 4 2 9 , 4 2 5 , 4 0 5 , 3 9 7 , 3 9 7 , 3 8 4 , 3 8 2 , 3 7 6 , 3 7 2 , 3 7 2 , 3 9 3 , 3 8 4 , 3 9 3 , 3 9 7 , 4 0 3 , 4 1 5 , 4 2 7 , 4 2 5 , 4 3 3 , 4 4 2 , 4 3 5 , 4 4 4 , 4 4 6 , 4 4 8 , 4 4 8 , 4 5 4 , 4 5 0 , 4 6 0 , 4 6 6 , 4 6 0 , 4 6 0 , 4 7 4 , 4 7 4 , 4 8 2 , 4 9 3 , 4 9 3 , 4 9 9 , 4 9 5 , 5 0 7 , 5 1 1 , 4 9 9 , 5 0 9 , 5 1 5 , 5 1 1 , 5 1 3 , 5 0 9 , 4 9 7 , 4 9 1 , 4 9 3 , 4 8 0 , 4 7 6 , 4 6 6 , 4 4 6 , 4 4 2 , 4 3 8 , 4 3 1 , 4 2 5 , 4 0 5 , 4 1 9 , 3 9 1 , 3 9 3 , 4 0 7 , 4 0 7 , 4 0 1 , 3 9 5 , 4 1 1 , 4 1 3 , 4 2 5 , 4 3 1 , 4 3 8 , 4 4 6 , 4 5 6 , 4 6 4 , 4 6 0 , 4 6 4 , 4 7 8 , 4 8 4 , 4 8 0 , 4 8 0 , 4 7 6 , 4 8 4 , 4 9 5 , 5 0 1 , 5 0 9 , 5 1 3 , 5 1 7 , 5 1 5 , 5 2 3 , 5 4 2 , 5 2 9 , 5 2 9 , 5 5 0 , 5 5 6 , 5 3 6 , 5 3 8 , 5 4 8 , 5 2 9 , 5 3 4 , 5 3 4 , 5 2 5 , 5 2 1 , 5 1 9 , 5 1 3 , 5 0 7 , 4 8 9 , 4 8 9 , 4 6 0 , 4 4 8 , 4 6 0 , 4 4 2 , 4 5 2 , 4 5 4 , 4 3 5 , 4 2 7 , 4 3 3 , 4 3 8 , 4 3 5 , 4 4 2 , 4 5 0 , 4 5 2 , 4 6 0 , 4 6 8 , 4 7 6 , 4 7 6 , 4 8 2 , 4 8 9 , 4 9 3 , 5 0 7 , 4 9 9 , 4 9 5 , 5 0 9 , 5 1 3 , 5 1 9 , 5 2 5 , 5 2 1 , 5 3 6 , 5 3 6 , 5 5 0 , 5 3 8 , 5 6 4 , 5 5 6 , 5 5 6 , 5 7 0 , 5 5 8 , 5 5 0 , 5 6 0 , 5 6 6 , 5 5 8 , 5 5 0 , 5 5 6 , 5 5 4 , 5 4 4 , 5 4 4 , 5 2 3 , 5 2 3 , 5 1 1 , 5 0 3 , 5 0 3 , 4 9 5 , 4 9 5 , 4 6 4 , 4 5 6 , 4 6 8 , 4 6 0 , 4 6 0 , 4 6 2 , 4 6 8 , 4 5 6 , 4 5 8 , 4 6 0 , 4 7 0 , 4 7 2 , 4 8 2 , 4 9 3 , 4 9 3 , 4 9 9 , 5 0 3 , 5 0 9 , 5 1 3 , 5 1 5 , 5 1 7 , 5 3 4 , 5 3 1 , 5 2 9 , 5 2 7 , 5 3 4 , 5 4 0 , 5 4 2 , 5 4 6 , 5 4 0 , 5 4 8 , 5 4 8 , 5 4 2 , 5 5 4 , 5 7 0 , 5 6 4 , 5 8 0 , 5 8 5 , 5 7 8 , 5 7 6 , 5 7 0 , 5 7 6 , 5 6 2 , 5 7 0 , 5 5 8 , 5 5 6 , 5 5 0 , 5 2 3 , 5 3 4 , 5 2 1 , 5 1 1 , 5 0 5 , 4 7 8 , 4 7 0 , 4 6 8 , 4 6 2 , 4 6 4 , 4 6 4 , 4 5 6 , 4 6 8 , 4 7 0 , 4 8 7 , 4 8 4 , 4 8 9 , 4 9 9 , 5 0 9 , 5 0 5 , 5 1 7 , 5 2 3 , 5 2 5 , 5 3 1 , 5 3 1 , 5 3 1 , 5 3 1 , 5 4 4 , 5 4 8 , 5 5 8 , 5 5 6 , 5 4 8 , 5 5 0 , 5 4 2 , 5 5 4 , 5 7 2 , 5 7 8 , 5 8 9 , 5 9 7 , 6 0 3 , 6 0 1 , 6 0 1 , 5 9 5 , 6 0 3 , 6 0 5 , 5 9 5 , 5 8 3 , 5 8 0 , 5 7 0 , 5 7 2 , 5 6 6 , 5 5 4 , 5 6 2 , 5 5 0 , 5 3 8 , 5 3 1 , 5 2 9 , 4 9 9 , 5 0 7 , 5 1 3 , 4 9 5 , 4 8 2 , 4 8 2 , 4 9 5 , 5 0 9 , 5 0 1 , 5 1 5 , 5 2 5 , 5 2 1 , 5 2 7 , 5 3 8 , 5 3 8 , 5 4 2 , 5 5 2 , 5 5 8 , 5 6 4 , 5 6 8 , 5 6 8 , 5 7 2 , 5 7 6 , 5 8 3 , 5 9 1 , 5 9 3 , 5 9 5 , 5 9 9 , 6 0 3 , 6 1 1 , 6 1 7 , 6 1 3 , 6 2 5 , 6 2 3 , 6 4 0 , 6 4 4 , 6 4 6 , 6 4 8 , 6 5 4 , 6 5 2 , 6 4 6 , 6 5 2 , 6 4 2 , 6 3 4 , 6 2 9 , 6 3 2 , 6 2 1 , 6 0 1 , 6 0 3 , 6 0 1 , 5 9 1 , 5 8 7 , 5 7 0 , 5 6 8 , 5 5 2 , 5 5 6 , 5 4 2 , 5 3 1 , 5 4 0 , 5 4 8 , 5 4 8 , 5 4 2 , 5 5 0 , 5 6 0 , 5 6 4 , 5 7 0 , 5 8 0 , 5 7 4 , 5 7 2 , 5 6 4 , 5 7 4 , 5 7 8 , 5 8 5 , 5 8 9 , 5 9 7 , 6 1 1 , 6 1 7 , 6 1 3 , 6 1 3 , 6 1 5 , 6 2 5 , 6 4 4 , 6 4 2 , 6 3 2 , 6 5 0 , 6 4 4 , 6 6 0 , 6 6 4 , 6 6 0 , 6 6 2 , 6 6 6 , 6 5 8 , 6 6 0 , 6 4 2 , 6 4 2 , 6 4 6 , 6 3 6 , 6 3 6 , 6 2 5 , 6 0 9 , 6 2 1 , 6 0 1 , 5 9 9 , 5 8 5 , 5 7 8 , 5 6 2 , 5 6 0 , 5 4 6 , 5 3 8 , 5 4 6 , 5 4 6 , 5 4 0 , 5 5 0 , 5 5 4 , 5 5 8 , 5 6 0 , 5 7 6 , 5 7 2 , 5 7 4 , 5 9 1 , 5 9 5 , 5 9 7 , 5 9 5 , 5 9 9 , 5 9 7 , 6 0 5 , 6 2 3 , 6 2 3 , 6 2 9 , 6 2 1 , 6 3 6 , 6 3 8 , 6 3 4 , 6 4 0 , 6 4 6 , 6 5 2 , 6 6 2 , 6 7 2 , 6 7 2 , 6 6 4 , 6 8 1 , 6 8 1 , 6 7 6 , 6 7 6 , 6 8 5 , 6 7 8 , 6 6 8 , 6 7 0 , 6 6 4 , 6 5 6 , 6 4 2 , 6 2 1 , 6 3 2 , 6 1 7 , 6 1 5 , 6 0 7 , 5 8 7 , 5 7 6 , 5 8 9 , 5 7 0 , 5 6 0 , 5 6 4 , 5 6 0 , 5 6 0 , 5 7 0 , 5 7 6 , 5 8 7 , 5 8 5 , 5 8 3 , 5 9 1 , 6 0 3 , 6 0 7 , 6 1 1 , 6 2 3 , 6 2 5 , 6 3 2 , 6 3 2 , 6 3 6 , 6 3 8 , 6 4 6 , 6 4 4 , 6 5 2 , 6 6 6 , 6 5 0 , 6 5 8 , 6 7 4 , 6 6 4 , 6 8 9 , 6 9 7 , 6 8 7 , 6 9 1 , 6 9 3 , 6 9 7 , 6 8 9 , 6 9 5 , 7 1 1 , 6 9 9 , 6 8 9 , 6 9 5 , 6 8 9 , 6 7 4 , 6 7 0 , 6 5 8 , 6 5 0 , 6 4 4 , 6 3 6 , 6 1 3 , 6 1 3 , 6 0 1 , 5 9 5 , 6 0 1 , 5 8 7 , 5 6 8 , 5 7 6 , 5 8 0 , 5 9 3 , 5 8 3 , 5 8 0 , 5 9 7 , 6 0 9 , 6 1 1 , 6 1 5 , 6 2 3 , 6 2 7 , 6 4 0 , 6 4 6 , 6 5 2 , 6 5 0 , 6 6 4 , 6 6 6 , 6 6 6 , 6 7 0 , 6 6 8 , 6 7 0 , 6 7 4 , 6 8 5 , 6 9 5 , 7 0 5 , 7 0 3 , 7 1 3 , 7 2 1 , 7 2 3 , 7 2 5 , 7 3 8 , 7 4 0 , 7 3 2 , 7 4 0 , 7 3 8 , 7 3 2 , 7 3 0 , 7 2 5 , 7 2 3 , 7 1 3 , 7 0 5 , 7 0 5 , 6 9 5 , 6 7 6 , 6 6 2 , 6 6 0 , 6 5 8 , 6 5 8 , 6 4 4 , 6 2 5 , 6 4 4 , 6 1 9 , 6 0 9 , 6 1 9 , 6 3 2 , 6 3 2 , 6 3 6 , 6 4 4 , 6 4 2 , 6 5 2 , 6 5 8 , 6 6 6 , 6 7 2 , 6 7 8 , 6 8 7 , 6 9 5 , 6 8 7 , 6 9 5 , 7 1 1 , 7 2 1 , 7 0 3 , 7 0 5 , 7 1 5 , 7 1 7 , 7 2 7 , 7 2 5 , 7 4 0 , 7 5 0 , 7 4 4 , 7 6 2 , 7 6 2 , 7 5 2 , 7 6 4 , 7 6 4 , 7 6 6 , 7 6 0 , 7 6 2 , 7 7 2 , 7 6 8 , 7 6 0 , 7 5 0 , 7 5 6 , 7 3 8 , 7 3 8 , 7 2 1 , 7 1 5 , 7 0 5 , 6 9 9 , 6 9 1 , 6 8 9 , 6 7 8 , 6 5 8 , 6 4 4 , 6 4 8 , 6 5 6 , 6 4 4 , 6 5 0 , 6 6 2 , 6 6 4 , 6 7 2 , 6 7 8 , 6 7 8 , 6 8 7 , 6 9 3 , 6 9 9 , 7 0 5 , 7 0 5 , 7 0 9 , 7 0 9 , 7 2 1 , 7 4 0 , 7 4 2 , 7 4 2 , 7 3 4 , 7 3 8 , 7 3 8 , 7 4 6 , 7 5 8 , 7 5 2 , 7 8 5 , 7 8 1 , 7 6 6 , 7 7 7 , 7 8 9 , 7 9 7 , 7 9 1 , 7 8 1 , 8 0 1 , 7 9 7 , 8 0 3 , 7 9 5 , 7 8 3 , 7 8 3 , 7 8 5 , 7 6 8 , 7 6 0 , 7 5 0 , 7 4 0 , 7 4 4 , 7 3 4 , 7 2 5 , 6 9 3 , 6 9 1 , 6 8 3 , 6 8 7 , 6 6 6 , 6 8 5 , 6 8 5 , 6 8 1 , 6 7 6 , 6 8 5 , 6 9 7 , 6 9 9 , 7 1 3 , 7 1 5 , 7 2 1 , 7 3 4 , 7 3 8 , 7 4 0 , 7 5 2 , 7 5 6 , 7 5 2 , 7 7 0 , 7 7 2 , 7 6 4 , 7 6 6 , 7 7 7 , 7 6 8 , 7 9 1 , 7 9 5 , 8 0 5 , 8 1 5 , 8 2 6 , 8 1 3 , 8 2 3 , 8 1 9 , 8 2 6 , 8 3 6 , 8 3 2 , 8 3 2 , 8 2 3 , 8 4 0 , 8 3 2 , 8 3 2 , 8 2 1 , 8 1 3 , 8 1 3 , 7 9 9 , 7 7 4 , 7 8 3 , 7 6 2 , 7 5 8 , 7 5 8 , 7 5 8 , 7 4 4 , 7 3 6 , 7 1 7 , 7 0 7 , 7 2 3 , 7 1 9 , 7 1 9 , 7 2 5 , 7 3 2 , 7 3 6 , 7 4 2 , 7 4 6 , 7 5 0 , 7 5 2 , 7 5 8 , 7 6 6 , 7 7 0 , 7 7 9 , 7 8 3 , 7 8 7 , 7 9 1 , 7 9 1 , 7 9 5 , 8 1 5 , 8 0 5 , 8 0 9 , 8 2 8 , 8 1 9 , 8 2 6 , 8 4 2 , 8 4 8 , 8 5 4 , 8 5 4 , 8 6 0 , 8 5 2 , 8 6 4 , 8 6 6 , 8 6 2 , 8 6 0 , 8 6 0 , 8 5 8 , 8 5 6 , 8 4 2 , 8 3 8 , 8 2 6 , 8 2 1 , 7 9 9 , 8 0 9 , 7 9 5 , 7 8 3 , 7 7 2 , 7 5 4 , 7 5 8 , 7 4 8 , 7 4 4 , 7 3 8 , 7 2 1 , 7 3 0 , 7 3 6 , 7 4 6 , 7 4 8 , 7 5 4 , 7 6 0 , 7 6 6 , 7 7 4 , 7 9 1 , 7 8 9 , 7 9 3 , 7 9 7 , 8 0 9 , 8 0 9 , 8 1 1 , 8 1 9 , 8 2 8 , 8 3 0 , 8 4 4 , 8 2 8 , 8 2 8 , 8 4 8 , 8 5 8 , 8 5 8 , 8 6 0 , 8 6 2 , 8 6 4 , 8 7 2 , 8 7 7 , 8 9 1 , 8 8 3 , 8 7 9 , 8 9 1 , 8 8 9 , 8 8 9 , 8 7 5 , 8 7 7 , 8 7 5 , 8 6 4 , 8 5 6 , 8 4 6 , 8 4 6 , 8 4 2 , 8 3 2 , 8 1 5 , 8 0 5 , 7 9 9 , 7 7 0 , 7 8 1 , 7 7 7 , 7 6 0 , 7 4 2 , 7 5 0 , 7 6 4 , 7 5 6 , 7 6 2 , 7 7 9 , 7 7 2 , 7 8 9 , 7 9 9 , 8 0 1 , 8 0 1 , 8 1 3 , 8 1 9 , 8 2 1 , 8 2 3 , 8 3 4 , 8 3 6 , 8 3 0 , 8 4 0 , 8 4 6 , 8 6 0 , 8 5 6 , 8 6 2 , 8 5 2 , 8 5 6 , 8 8 7 , 8 8 3 , 8 8 7 , 9 0 3 , 9 0 7 , 9 1 3 , 9 1 5 , 9 1 5 , 9 2 1 , 9 2 4 , 9 2 1 , 9 1 9 , 9 1 9 , 9 0 7 , 9 0 5 , 9 0 1 , 8 9 7 , 8 8 1 , 8 7 9 , 8 5 8 , 8 6 6 , 8 4 0 , 8 4 8 , 8 4 2 , 8 0 3 , 8 0 3 , 8 0 1 , 8 0 3 , 8 0 1 , 7 9 9 , 8 0 7 , 8 0 9 , 8 1 1 , 8 2 1 , 8 2 6 , 8 2 8 , 8 4 0 , 8 4 2 , 8 6 2 , 8 7 2 , 8 7 9 , 8 7 5 , 8 8 1 , 8 7 5 , 8 7 7 , 8 8 9 , 8 9 3 , 8 9 7 , 8 9 3 , 8 9 9 , 9 0 3 , 9 0 5 , 9 1 5 , 9 1 9 , 9 5 6 , 9 5 6 , 9 6 2 , 9 5 4 , 9 4 8 , 9 4 8 , 9 4 8 , 9 4 4 , 9 3 4 , 9 3 2 , 9 2 4 , 9 1 5 , 9 1 1 , 8 9 5 , 8 8 7 , 8 8 9 , 8 6 8 , 8 4 6 , 8 3 8 , 8 1 7 , 8 3 2 , 8 3 2 , 8 2 1 , 8 2 8 , 8 3 2 , 8 4 4 , 8 3 8 , 8 4 6 , 8 5 8 , 8 6 8 , 8 8 1 , 8 7 9 , 8 8 5 , 8 9 1 , 8 9 7 , 8 9 7 , 9 0 1 , 9 0 7 , 9 0 7 , 9 0 7 , 9 2 6 , 9 1 7 , 9 2 4 , 9 3 4 , 9 4 2 , 9 5 0 , 9 5 8 , 9 6 2 , 9 7 3 , 9 6 8 , 9 6 8 , 9 7 9 , 9 8 5 , 9 8 5 , 9 9 5 , 9 9 1 , 9 7 1 , 9 8 9 , 9 7 7 , 9 7 3 , 9 6 6 , 9 5 6 , 9 4 6 , 9 4 4 , 9 3 6 , 9 2 1 , 9 0 1 , 8 9 7 , 8 9 3 , 8 8 1 , 8 9 1 , 8 7 2 , 8 5 4 , 8 4 8 , 8 5 4 , 8 5 6 , 8 6 8 , 8 7 0 , 8 7 2 , 8 8 1 , 8 9 1 , 8 9 9 , 9 1 3 , 9 1 3 , 9 1 9 , 9 0 9 , 9 3 4 , 9 3 6 , 9 2 8 , 9 3 2 , 9 3 6 , 9 3 2 , 9 4 4 , 9 5 0 , 9 5 2 , 9 4 8 , 9 4 0 , 9 5 2 , 9 9 1 , 9 8 5 , 9 9 3 , 9 9 7 , 9 9 5 , 1 0 1 3 , 1 0 0 7 , 1 0 1 1 , 1 0 1 3 , 1 0 1 1 , 1 0 1 1 , 1 0 0 3 , 9 9 9 , 9 9 7 , 9 8 7 , 9 8 1 , 9 6 2 , 9 6 0 , 9 5 6 , 9 4 0 , 9 3 2 , 9 1 7 , 9 1 9 , 9 1 1 , 9 0 7 , 9 1 3 , 8 9 5 , 8 9 7 , 8 8 5 , 8 8 9 , 8 8 5 , 8 9 7 , 9 0 9 , 9 1 3 , 9 1 9 , 9 2 1 , 9 3 6 , 9 4 6 , 9 4 2 , 9 4 6 , 9 4 8 , 9 6 0 , 9 7 5 , 9 7 3 , 9 6 6 , 9 6 8 , 9 6 6 , 9 7 3 , 9 7 9 , 9 9 7 , 9 8 5 , 9 9 3 , 1 0 0 3 , 1 0 1 3 , 1 0 2 6 , 1 0 1 3 , 1 0 3 2 , 1 0 3 6 , 1 0 3 8 , 1 0 5 0 , 1 0 4 4 , 1 0 4 8 , 1 0 4 4 , 1 0 4 2 , 1 0 3 2 , 1 0 3 0 , 1 0 2 8 , 1 0 0 3 , 1 0 0 5 , 9 8 5 , 9 9 9 , 9 8 9 , 9 7 1 , 9 8 1 , 9 6 8 , 9 4 2 , 9 4 8 , 9 4 0 , 9 3 2 , 9 2 4 , 9 2 1 , 9 3 4 , 9 3 8 , 9 4 4 , 9 4 6 , 9 5 4 , 9 6 0 , 9 7 1 , 9 8 3 , 9 8 1 , 9 8 5 , 9 9 1 , 9 9 3 , 1 0 0 3 , 1 0 1 3 , 1 0 1 3 , 1 0 2 4 , 1 0 3 4 , 1 0 4 6 , 1 0 3 6 , 1 0 4 0 , 1 0 6 0 , 1 0 6 6 , 1 0 4 6 , 1 0 4 4 , 1 0 5 4 , 1 0 7 3 , 1 0 8 1 , 1 0 7 3 , 1 0 9 1 , 1 0 9 5 , 1 0 8 5 , 1 0 9 7 , 1 1 0 1 , 1 0 9 5 , 1 0 9 3 , 1 0 9 5 , 1 0 8 3 , 1 0 7 3 , 1 0 7 1 , 1 0 6 0 , 1 0 6 2 , 1 0 4 8 , 1 0 3 2 , 1 0 2 8 , 1 0 1 5 , 1 0 1 7 , 1 0 0 1 , 9 9 5 , 9 8 3 , 9 8 7 , 9 7 1 , 9 8 5 , 9 8 5 , 9 8 1 , 9 9 7 , 9 9 3 , 1 0 0 3 , 1 0 0 5 , 1 0 1 1 , 1 0 1 7 , 1 0 2 0 , 1 0 3 0 , 1 0 4 2 , 1 0 3 6 , 1 0 5 8 , 1 0 6 4 , 1 0 6 9 , 1 0 6 0 , 1 0 7 1 , 1 0 6 6 , 1 0 6 2 , 1 0 7 5 , 1 0 7 9 , 1 0 7 3 , 1 0 7 9 ,',)"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 58
    }
   ],
   "source": [
    "input_strs"
   ],
   "id": "239cfbe6d9a849f8",
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T10:07:08.262356Z",
     "start_time": "2024-01-26T10:07:08.219802Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "steps = len(test[0])\n",
    "samples = None\n",
    "medians = None\n",
    "completions_list = None"
   ],
   "id": "1f8c8f5efa4fa818",
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "id": "bed419f23f994290"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
