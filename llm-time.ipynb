{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-28T10:46:24.078635Z",
     "start_time": "2024-02-28T10:46:24.073068Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain import HuggingFaceHub\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(40,)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_points = 40\n",
    "frequency1 = 1\n",
    "amplitude1 = 5\n",
    "frequency2 = 2\n",
    "amplitude2 = 3\n",
    "frequency3 = 0.5\n",
    "amplitude3 = 7\n",
    "time_index = pd.date_range(start=\"2022-01-01\", periods=num_points, freq=\"D\")\n",
    "sine_series_complicated = (\n",
    "    amplitude1 * np.sin(2 * np.pi * frequency1 * np.arange(num_points) / num_points) +\n",
    "    amplitude2 * np.sin(2 * np.pi * frequency2 * np.arange(num_points) / num_points) +\n",
    "    amplitude3 * np.sin(2 * np.pi * frequency3 * np.arange(num_points) / num_points)\n",
    ")\n",
    "sine_series_complicated = pd.Series(sine_series_complicated, index=time_index, name=\"ComplicatedSine\")\n",
    "sine_series_complicated.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T10:45:00.663615Z",
     "start_time": "2024-02-28T10:45:00.658246Z"
    }
   },
   "id": "3de1f370383e0a39",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train = sine_series_complicated.iloc[:300]\n",
    "test = sine_series_complicated.iloc[300:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T10:45:05.627384Z",
     "start_time": "2024-02-28T10:45:05.621918Z"
    }
   },
   "id": "c9606e672dca5020",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Scaler:\n",
    "    transform: callable = lambda x: x\n",
    "    inv_transform: callable = lambda x: x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T10:45:09.709802Z",
     "start_time": "2024-02-28T10:45:09.704301Z"
    }
   },
   "id": "32bc96ae59ac39a3",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LLMTime:\n",
    "    \n",
    "    def __init__(self, train, test, alpha=0.95, beta=0.3, batch_length=400, basic=False, temperature=0.5, do_sample=True, model_name=\"mistralai/Mistral-7B-v0.1\", repetition_penalty=1.0):\n",
    "        self.model_name = model_name\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.batch_length = batch_length\n",
    "        self.basic = basic\n",
    "        self.temperature = temperature\n",
    "        self.do_sample = do_sample\n",
    "        self.repetition_penalty = repetition_penalty\n",
    "        self.scalers = None\n",
    "        self.input_str = None\n",
    "        self.test_str = None\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.good_tokens = None\n",
    "        self.bad_tokens = None\n",
    "        self.output = None\n",
    "        self.transformed_output_arr = None\n",
    "        self.preprocess_data()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_scaler(history, alpha=0.95, beta=0.3, basic=False):\n",
    "        history = history[~np.isnan(history)]\n",
    "        if basic:\n",
    "            q = np.maximum(np.quantile(np.abs(history), alpha),.01)\n",
    "            def transform(x):\n",
    "                return x / q\n",
    "            def inv_transform(x):\n",
    "                return x * q\n",
    "        else:\n",
    "            min_ = np.min(history) - beta*(np.max(history)-np.min(history))\n",
    "            q = np.quantile(history-min_, alpha)\n",
    "            if q == 0:\n",
    "                q = 1\n",
    "            def transform(x):\n",
    "                return (x - min_) / q\n",
    "            def inv_transform(x):\n",
    "                return x * q + min_\n",
    "        return Scaler(transform=transform, inv_transform=inv_transform)\n",
    "    \n",
    "    def convert_array_to_string(self, arr):\n",
    "        rounded_values = [round(val * 1000) for val in arr]\n",
    "        str_values = [str(val) for val in rounded_values]\n",
    "        result_string = \",\".join(str_values)\n",
    "        return result_string\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        train = self.train\n",
    "        test = self.test\n",
    "        if not isinstance(train, list):\n",
    "            train = [train]\n",
    "            test = [test]\n",
    "        n_val = len(train)\n",
    "        for i in range(len(train)):\n",
    "            if not isinstance(train[i], pd.Series):\n",
    "                train[i] = pd.Series(train[i], index=pd.RangeIndex(len(train[i])))\n",
    "                test[i] = pd.Series(test[i], index=pd.RangeIndex(len(train[i]), len(test[i])+len(train[i])))\n",
    "        alpha = self.alpha\n",
    "        beta = self.beta\n",
    "        basic = self.basic\n",
    "        self.scalers = [self.get_scaler(train[i].values, alpha=alpha, beta=beta, basic=basic) for i in range(len(train))]\n",
    "        input_arrs = [train[i].values for i in range(len(train))]\n",
    "        transformed_input_arrs = np.array([scaler.transform(input_array) for input_array, scaler in zip(input_arrs, self.scalers)])\n",
    "        input_str = self.convert_array_to_string(transformed_input_arrs[0])\n",
    "        test_arrs = [test[i].values for i in range(len(test))]\n",
    "        transformed_test_arrs = np.array([scaler.transform(input_array) for input_array, scaler in zip(test_arrs, self.scalers)])\n",
    "        test_str = self.convert_array_to_string(transformed_test_arrs[0])\n",
    "        self.input_str = input_str\n",
    "        self.test_str = test_str\n",
    "        return input_str, test_str, self.scalers\n",
    "    \n",
    "    def zero_shot(self):\n",
    "        torch.cuda.empty_cache()\n",
    "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name, device_map=\"auto\", load_in_4bit=True\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_name, padding_side=\"left\")\n",
    "        good_tokens_str = list(\"0123456789,\")\n",
    "        good_tokens = [tokenizer.convert_tokens_to_ids(token) for token in good_tokens_str]\n",
    "        bad_tokens = [i for i in range(len(tokenizer)) if i not in good_tokens]\n",
    "        input_str = self.input_str\n",
    "        for i in tqdm(range(self.batch_length, len(input_str) - self.batch_length, self.batch_length//10)):\n",
    "              batch_str = input_str[i-self.batch_length: i]\n",
    "              model_inputs = tokenizer(batch_str, return_tensors='pt').to('cuda')\n",
    "              generated_ids = model.generate(**model_inputs, do_sample=self.do_sample, max_new_tokens=self.batch_length//10, temperature=self.temperature, repetition_penalty=self.temperature, bad_words_ids=[[t] for t in bad_tokens], force_words_ids=[[t] for t in good_tokens])\n",
    "              output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "              print(f\"Batch: {batch_str}\")\n",
    "              print(f\"Actual: {input_str[i: i+self.batch_length//10]}\")\n",
    "              print(f\"Total: {input_str}\")\n",
    "              print(f\"Pred: {output[-self.batch_length//10:]}\")\n",
    "        inp = input_str[-self.batch_length:]\n",
    "        model_inputs = tokenizer(inp, return_tensors='pt').to(self.device)\n",
    "        generated_ids = model.generate(**model_inputs, do_sample=self.do_sample, max_new_tokens=self.batch_length//10, temperature=self.temperature, repetition_penalty=self.temperature, bad_words_ids=[[t] for t in bad_tokens], force_words_ids=[[t] for t in good_tokens])\n",
    "        output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return output\n",
    "    \n",
    "    @staticmethod    \n",
    "    def invert_string_to_array(string_values):\n",
    "        string_values = string_values.replace(\" \", \"\")\n",
    "        if string_values[-1] == ',':\n",
    "            string_values = string_values[:len(string_values) - 1]\n",
    "        str_values_list = string_values.split(',')\n",
    "        float_values = [float(val) if val.strip() != '' else 0.0 for val in str_values_list]\n",
    "        original_values = [val / 1000 for val in float_values]\n",
    "        return original_values\n",
    "\n",
    "    def get_original_array(self, output_str):\n",
    "        output_arr = self.invert_string_to_array(string_values=output_str)\n",
    "        output_arr = np.array(output_arr)\n",
    "        transformed_output_arr = self.scalers[0].inv_transform(output_arr)\n",
    "        self.transformed_output_arr = transformed_output_arr\n",
    "        return transformed_output_arr\n",
    "    \n",
    "    def plot(self, input, output, m):\n",
    "        model_parameters = {\n",
    "            \"alpha\": self.alpha,\n",
    "            \"beta\": self.beta,\n",
    "            \"batch_length\": self.batch_length,\n",
    "            \"basic\": self.basic,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"do_sample\": self.do_sample,\n",
    "            \"repetition_penalty\": self.repetition_penalty\n",
    "        }\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        plt.title(f\"Few Shot {self.model_name}\")\n",
    "        \n",
    "        # Add a vertical line at x = m\n",
    "        plt.axvline(x=m, color='k', linestyle='--', label='Train-Test Split')\n",
    "        plt.plot(output, color='red', label='Predicted')\n",
    "        plt.plot(input, color='blue', label='Actual')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Time')\n",
    "        sns.set_palette(\"husl\")\n",
    "        \n",
    "        textstr = '\\n'.join([f\"{key}: {value}\" for key, value in model_parameters.items()])\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        ax.text(1.05, 0.5, textstr, transform=ax.transAxes, fontsize=10, verticalalignment='center', bbox=props)\n",
    "        \n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        filename = f\"plots/mistral-few-shot-{current_time}.png\"\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def run(self):\n",
    "        self.zero_shot()\n",
    "        output = self.output\n",
    "        return output\n",
    "        \n",
    "    def plot_and_return(self, output):\n",
    "        transformed_output_arr = self.get_original_array(self.input_str + ',' + output)\n",
    "        input_arr = self.get_original_array(self.input_str + ',' + self.test_str)\n",
    "        inp = self.get_original_array(self.input_str)\n",
    "        m = len(inp)\n",
    "        input_arr = input_arr[:len(transformed_output_arr)]\n",
    "        self.plot(input_arr, transformed_output_arr, m)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9777b030e2558966"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
